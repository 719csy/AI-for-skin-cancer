{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxV68cM4YKIx34UjUBPJTt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/719csy/AI-for-skin-cancer/blob/main/ISIC_Task1%2B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8yGQ1eaMelp",
        "outputId": "06e5f971-95a9-4e99-899a-a1c96f26be33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Unmount the drive if it's currently mounted\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "# Ensure the mountpoint is clean by removing and recreating the directory\n",
        "if os.path.exists('/content/drive'):\n",
        "    # os.rmdir('/content/drive')  # This only works for empty directories\n",
        "    # More robust way to remove a directory and its contents\n",
        "    !rm -rf /content/drive/*\n",
        "    !rmdir /content/drive\n",
        "os.makedirs('/content/drive', exist_ok=True)\n",
        "\n",
        "# Now, mount the drive with force_remount=True\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP_fMFDd-rGZ",
        "outputId": "5f0c4893-7e48-4a07-83d6-dcefa4476418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "PS_-gQfMSigA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(CLS_LABEL_CSV)\n",
        "print(df.columns.tolist()[:30])\n",
        "print(df.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FAcqOyXPn8g",
        "outputId": "3d7e66e5-527f-4c3d-8c4e-a4bf17c97a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
            "          image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
            "0  ISIC_0024306  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
            "1  ISIC_0024307  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "h3W8MUhiTVP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Hybrid CNN–ViT–U-Net (Seg + Cls) with NEW AMP API + resume\n",
        "# ISIC 2018 Task 1 (Seg) + Task 3 (Cls)\n",
        "# Physical size: 15mm × 15mm → 256 × 256 px\n",
        "#\n",
        "# Speed controls:\n",
        "# - steps_per_epoch (cap per epoch steps)\n",
        "# - MC Dropout only every mc_every epochs (otherwise fast MC)\n",
        "# - validation caps (val_max_batches_seg/cls)\n",
        "# - workers=2\n",
        "#\n",
        "# Resume:\n",
        "# - load best.pt if exists else latest epoch_XXX.pt\n",
        "# - continue from ckpt_epoch + 1\n",
        "# =========================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import time, math, random, gc, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "# =========================================================\n",
        "# Performance settings\n",
        "# =========================================================\n",
        "cv2.setNumThreads(0)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Optional: keep current TF32 style (ok). If you want to silence new TF32 warnings,\n",
        "# you can REMOVE old flags. We'll only set matmul precision (recommended).\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "# =========================================================\n",
        "# Paths\n",
        "# =========================================================\n",
        "SEG_IMAGE_DIR = Path(\"/content/drive/My Drive/isic2018/images\")\n",
        "SEG_MASK_DIR  = Path(\"/content/drive/My Drive/isic2018/masks\")\n",
        "\n",
        "CLS_IMAGE_DIR = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_Input\".strip())\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\".strip())\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"/content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net\".strip())\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "EXPORT_DIR = CHECKPOINT_DIR.parent / \"exports\"\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# =========================================================\n",
        "# Physical size definition\n",
        "# =========================================================\n",
        "FIELD_SIZE_MM = 15.0\n",
        "IMAGE_SIZE = 256\n",
        "MM_PER_PIXEL = FIELD_SIZE_MM / IMAGE_SIZE\n",
        "\n",
        "# =========================================================\n",
        "# Utils\n",
        "# =========================================================\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def save_map_with_mm_axis(path_png: Path, arr: np.ndarray, title: str):\n",
        "    arr = np.asarray(arr)\n",
        "    # robust shape handling (avoid imshow crash)\n",
        "    if arr.ndim == 1:\n",
        "        if arr.size == IMAGE_SIZE * IMAGE_SIZE:\n",
        "            arr = arr.reshape(IMAGE_SIZE, IMAGE_SIZE)\n",
        "        else:\n",
        "            x_mm = np.linspace(0, FIELD_SIZE_MM, arr.size)\n",
        "            plt.figure(figsize=(5, 3), dpi=150)\n",
        "            plt.plot(x_mm, arr)\n",
        "            plt.xlabel(\"x (mm)\")\n",
        "            plt.ylabel(\"value\")\n",
        "            plt.title(title + f\" (1D, shape={arr.shape})\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(path_png, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "            return\n",
        "    if arr.ndim != 2:\n",
        "        print(f\"[WARN] Skip saving {title}: invalid shape={arr.shape}\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(5, 4), dpi=150)\n",
        "    plt.imshow(arr, extent=(0, FIELD_SIZE_MM, FIELD_SIZE_MM, 0))\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    plt.xlabel(\"x (mm)\")\n",
        "    plt.ylabel(\"y (mm)\")\n",
        "    plt.title(title + f\" (shape={arr.shape})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path_png, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def latest_epoch_ckpt(ckpt_dir: Path) -> Path | None:\n",
        "    # match epoch_XXX.pt\n",
        "    pts = sorted(ckpt_dir.glob(\"epoch_*.pt\"))\n",
        "    if not pts:\n",
        "        return None\n",
        "    def key(p: Path):\n",
        "        m = re.search(r\"epoch_(\\d+)\\.pt$\", p.name)\n",
        "        return int(m.group(1)) if m else -1\n",
        "    pts = sorted(pts, key=key)\n",
        "    return pts[-1] if key(pts[-1]) >= 0 else None\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Segmentation (ISIC 2018 Task 1)\n",
        "# =========================================================\n",
        "class ISICSegDataset(Dataset):\n",
        "    def __init__(self, image_dir: Path, mask_dir: Path, image_size: int = 256):\n",
        "        self.image_paths = sorted(image_dir.glob(\"*.jpg\"))\n",
        "        self.mask_paths = [mask_dir / f\"{p.stem}_segmentation.png\" for p in self.image_paths]\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Cannot read mask: {mask_path}\")\n",
        "\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1)     # [3,H,W]\n",
        "        mask = torch.from_numpy(mask).unsqueeze(0)       # [1,H,W]\n",
        "        return {\"image\": img, \"mask\": mask}\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Classification (ISIC 2018 Task 3) supports one-hot CSV\n",
        "# =========================================================\n",
        "CLS_MAP_DX = {\n",
        "    \"MEL\": 2, \"BCC\": 2,\n",
        "    \"AKIEC\": 1,\n",
        "    \"NV\": 0, \"BKL\": 0, \"DF\": 0, \"VASC\": 0\n",
        "}\n",
        "\n",
        "class ISICClsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A) one-hot CSV:\n",
        "       columns: image, MEL, NV, BCC, AKIEC, BKL, DF, VASC\n",
        "    B) dx CSV:\n",
        "       columns: image_id, dx\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir: Path, label_csv: Path, image_size: int = 256):\n",
        "        self.image_dir = image_dir\n",
        "        self.df = pd.read_csv(label_csv)\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.df.columns = self.df.columns.str.strip()\n",
        "        cols = set(self.df.columns)\n",
        "\n",
        "        onehot_classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "        has_onehot = (\"image\" in cols) and all(c in cols for c in onehot_classes)\n",
        "        has_dx = (\"image_id\" in cols and \"dx\" in cols)\n",
        "\n",
        "        if not (has_onehot or has_dx):\n",
        "            raise ValueError(\n",
        "                \"Unsupported CSV columns. Expect either:\\n\"\n",
        "                \"A) one-hot: image + MEL,NV,BCC,AKIEC,BKL,DF,VASC\\n\"\n",
        "                \"or B) dx: image_id + dx\\n\"\n",
        "                f\"Got columns: {list(self.df.columns)}\"\n",
        "            )\n",
        "\n",
        "        self.records = []\n",
        "        if has_onehot:\n",
        "            for _, row in self.df.iterrows():\n",
        "                img_id = str(row[\"image\"]).strip()\n",
        "                malignant = (row[\"MEL\"] == 1) or (row[\"BCC\"] == 1)\n",
        "                intermediate = (row[\"AKIEC\"] == 1)\n",
        "                benign = (row[\"NV\"] == 1) or (row[\"BKL\"] == 1) or (row[\"DF\"] == 1) or (row[\"VASC\"] == 1)\n",
        "\n",
        "                if malignant:\n",
        "                    label = 2\n",
        "                elif intermediate:\n",
        "                    label = 1\n",
        "                elif benign:\n",
        "                    label = 0\n",
        "                else:\n",
        "                    continue\n",
        "                self.records.append((img_id, label))\n",
        "        else:\n",
        "            for _, row in self.df.iterrows():\n",
        "                dx = str(row[\"dx\"]).strip()\n",
        "                if dx not in CLS_MAP_DX:\n",
        "                    continue\n",
        "                img_id = str(row[\"image_id\"]).strip()\n",
        "                self.records.append((img_id, CLS_MAP_DX[dx]))\n",
        "\n",
        "        if len(self.records) == 0:\n",
        "            raise ValueError(\"No valid records parsed from CSV. Check labels/image ids.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id, label = self.records[idx]\n",
        "        img_path = self.image_dir / f\"{img_id}.jpg\"\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            img_path2 = self.image_dir / f\"{img_id}.png\"\n",
        "            img = cv2.imread(str(img_path2))\n",
        "            if img is None:\n",
        "                raise FileNotFoundError(f\"Cannot find image for id={img_id}: {img_path} or {img_path2}\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        return {\"image\": img, \"label\": torch.tensor(label, dtype=torch.long)}\n",
        "\n",
        "# =========================================================\n",
        "# Model blocks\n",
        "# =========================================================\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GELU()\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(ConvBNAct(in_ch, out_ch), ConvBNAct(out_ch, out_ch))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=32):\n",
        "        super().__init__()\n",
        "        self.e1 = ConvBlock(in_ch, base_ch)            # H\n",
        "        self.e2 = ConvBlock(base_ch, base_ch * 2)      # H/2\n",
        "        self.e3 = ConvBlock(base_ch * 2, base_ch * 4)  # H/4\n",
        "        self.e4 = ConvBlock(base_ch * 4, base_ch * 8)  # H/8\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "    def forward(self, x):\n",
        "        f1 = self.e1(x)\n",
        "        f2 = self.e2(self.pool(f1))\n",
        "        f3 = self.e3(self.pool(f2))\n",
        "        f4 = self.e4(self.pool(f3))\n",
        "        return [f1, f2, f3, f4]\n",
        "\n",
        "class ViTBottleneck(nn.Module):\n",
        "    def __init__(self, dim, depth=2, heads=4, drop=0.1):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=dim, nhead=heads, dim_feedforward=dim*4,\n",
        "            dropout=drop, activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, depth)\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        tokens = x.flatten(2).transpose(1, 2)  # [B,N,C]\n",
        "        tokens = self.encoder(tokens)\n",
        "        return tokens.transpose(1, 2).reshape(b, c, h, w)\n",
        "\n",
        "class UNetDecoder(nn.Module):\n",
        "    def __init__(self, base_ch=32, out_ch=1, dropout_p=0.10):\n",
        "        super().__init__()\n",
        "        self.up3 = nn.ConvTranspose2d(base_ch*8, base_ch*4, 2, 2)\n",
        "        self.d3  = ConvBlock(base_ch*8, base_ch*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base_ch*4, base_ch*2, 2, 2)\n",
        "        self.d2  = ConvBlock(base_ch*4, base_ch*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_ch*2, base_ch, 2, 2)\n",
        "        self.d1  = ConvBlock(base_ch*2, base_ch)\n",
        "        self.drop = nn.Dropout2d(dropout_p) if dropout_p > 0 else nn.Identity()\n",
        "        self.out  = nn.Conv2d(base_ch, out_ch, 1)\n",
        "    def forward(self, feats):\n",
        "        f1, f2, f3, f4 = feats\n",
        "        x = self.up3(f4)\n",
        "        x = self.d3(torch.cat([x, f3], dim=1))\n",
        "        x = self.up2(x)\n",
        "        x = self.d2(torch.cat([x, f2], dim=1))\n",
        "        x = self.up1(x)\n",
        "        x = self.d1(torch.cat([x, f1], dim=1))\n",
        "        x = self.drop(x)\n",
        "        return self.out(x)\n",
        "\n",
        "class HybridMTLModel(nn.Module):\n",
        "    def __init__(self, base_ch=32, num_classes=3, seg_dropout=0.10):\n",
        "        super().__init__()\n",
        "        self.encoder = ConvEncoder(3, base_ch)\n",
        "        self.bottleneck = ViTBottleneck(base_ch*8, depth=2, heads=4, drop=0.1)\n",
        "        self.decoder = UNetDecoder(base_ch, out_ch=1, dropout_p=seg_dropout)\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base_ch*8, base_ch*8),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(base_ch*8, num_classes),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x)\n",
        "        feats[-1] = self.bottleneck(feats[-1])\n",
        "        seg_logit = self.decoder(feats)\n",
        "        cls_logit = self.cls_head(feats[-1])\n",
        "        return seg_logit, cls_logit\n",
        "\n",
        "# =========================================================\n",
        "# Metrics (seg)\n",
        "# =========================================================\n",
        "def mask_to_boundary(mask: np.ndarray) -> np.ndarray:\n",
        "    mask_u8 = (mask > 0).astype(np.uint8)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    er = cv2.erode(mask_u8, kernel, iterations=1)\n",
        "    bd = (mask_u8 - er) > 0\n",
        "    return bd.astype(np.uint8)\n",
        "\n",
        "def bf_score(pred_mask: np.ndarray, gt_mask: np.ndarray, tol_px: int = 2) -> float:\n",
        "    pb = mask_to_boundary(pred_mask)\n",
        "    gb = mask_to_boundary(gt_mask)\n",
        "    if pb.sum() == 0 and gb.sum() == 0:\n",
        "        return 1.0\n",
        "    if pb.sum() == 0 or gb.sum() == 0:\n",
        "        return 0.0\n",
        "    dt_g = ndi.distance_transform_edt(1 - gb)\n",
        "    dt_p = ndi.distance_transform_edt(1 - pb)\n",
        "    prec = (dt_g[pb.astype(bool)] <= tol_px).mean() if pb.sum() > 0 else 0.0\n",
        "    rec  = (dt_p[gb.astype(bool)] <= tol_px).mean() if gb.sum() > 0 else 0.0\n",
        "    return float(2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "\n",
        "def hd95(pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:\n",
        "    pb = mask_to_boundary(pred_mask).astype(bool)\n",
        "    gb = mask_to_boundary(gt_mask).astype(bool)\n",
        "    if pb.sum() == 0 and gb.sum() == 0:\n",
        "        return 0.0\n",
        "    if pb.sum() == 0 or gb.sum() == 0:\n",
        "        h, w = pred_mask.shape\n",
        "        return float(math.sqrt(h*h + w*w))\n",
        "    dt_g = ndi.distance_transform_edt(~gb)\n",
        "    dt_p = ndi.distance_transform_edt(~pb)\n",
        "    d1 = dt_g[pb]\n",
        "    d2 = dt_p[gb]\n",
        "    all_d = np.concatenate([d1, d2], axis=0)\n",
        "    return float(np.percentile(all_d, 95))\n",
        "\n",
        "# =========================================================\n",
        "# Metrics (cls)\n",
        "# =========================================================\n",
        "def softmax_np(logits: np.ndarray) -> np.ndarray:\n",
        "    x = logits - logits.max(axis=1, keepdims=True)\n",
        "    e = np.exp(x)\n",
        "    return e / (e.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def ece_score(probs: np.ndarray, labels: np.ndarray, n_bins: int = 15) -> float:\n",
        "    conf = probs.max(axis=1)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    acc = (pred == labels).astype(np.float32)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        m = (conf > bins[i]) & (conf <= bins[i+1])\n",
        "        if m.any():\n",
        "            ece += abs(acc[m].mean() - conf[m].mean()) * m.mean()\n",
        "    return float(ece)\n",
        "\n",
        "def nll_score(probs: np.ndarray, labels: np.ndarray) -> float:\n",
        "    p = probs[np.arange(len(labels)), labels]\n",
        "    return float((-np.log(p + 1e-12)).mean())\n",
        "\n",
        "def brier_score(probs: np.ndarray, labels: np.ndarray) -> float:\n",
        "    n, k = probs.shape\n",
        "    y = np.zeros((n, k), dtype=np.float32)\n",
        "    y[np.arange(n), labels] = 1.0\n",
        "    return float(((probs - y) ** 2).sum(axis=1).mean())\n",
        "\n",
        "def predictive_entropy(p: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    if p.ndim >= 2 and p.shape[-1] > 1:\n",
        "        return -(p * np.log(p + eps)).sum(axis=-1)\n",
        "    return -(p*np.log(p+eps) + (1-p)*np.log(1-p+eps))\n",
        "\n",
        "def risk_coverage_curve(probs: np.ndarray, labels: np.ndarray, uncertainty: np.ndarray):\n",
        "    n = len(labels)\n",
        "    order = np.argsort(uncertainty)\n",
        "    probs_s = probs[order]\n",
        "    labels_s = labels[order]\n",
        "    pred = probs_s.argmax(axis=1)\n",
        "    err = (pred != labels_s).astype(np.float32)\n",
        "    coverages = np.linspace(1/n, 1.0, n)\n",
        "    risks = np.cumsum(err) / (np.arange(n) + 1)\n",
        "    return coverages, risks\n",
        "\n",
        "def aurc(coverages: np.ndarray, risks: np.ndarray) -> float:\n",
        "    # numpy 2.0 prefers trapezoid\n",
        "    return float(np.trapezoid(risks, coverages))\n",
        "\n",
        "# =========================================================\n",
        "# MC Dropout helpers (seg)\n",
        "# =========================================================\n",
        "def enable_dropout_only(model: nn.Module):\n",
        "    model.eval()\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
        "            m.train()\n",
        "\n",
        "def mutual_information(mc_probs: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    mean_p = mc_probs.mean(axis=0)\n",
        "    H_mean = predictive_entropy(mean_p, eps=eps)\n",
        "    H_each = predictive_entropy(mc_probs, eps=eps)\n",
        "    return H_mean - H_each.mean(axis=0)\n",
        "\n",
        "def compute_boundary_prob_from_plesion(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy)\n",
        "    g = g / (g.max() + 1e-12)\n",
        "    return g.astype(np.float32)\n",
        "\n",
        "def transition_width_map_mm(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy) + 1e-12\n",
        "    width_px = 0.6 / g\n",
        "    width_mm = width_px * MM_PER_PIXEL\n",
        "    return np.clip(width_mm, 0.0, 10.0).astype(np.float32)\n",
        "\n",
        "# =========================================================\n",
        "# Losses\n",
        "# =========================================================\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "ce  = nn.CrossEntropyLoss()\n",
        "\n",
        "def dice_loss_with_logits(logits, targets, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    num = 2 * (probs * targets).sum(dim=(2, 3))\n",
        "    den = (probs + targets).sum(dim=(2, 3)) + eps\n",
        "    return (1 - (num / den)).mean()\n",
        "\n",
        "# =========================================================\n",
        "# Config (workers=2 + speed controls + resume)\n",
        "# =========================================================\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    image_size: int = 256\n",
        "    batch_size: int = 8\n",
        "    epochs: int = 60\n",
        "\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-2\n",
        "\n",
        "    num_workers: int = 2   # ✅ requested\n",
        "\n",
        "    seg_w: float = 1.0\n",
        "    cls_w: float = 0.5\n",
        "    grad_clip: float = 1.0\n",
        "    val_ratio: float = 0.15\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # speed controls\n",
        "    steps_per_epoch: int = 350\n",
        "    mc_samples: int = 8\n",
        "    mc_samples_fast: int = 2\n",
        "    mc_every: int = 5\n",
        "    val_max_batches_seg: int = 120\n",
        "    val_max_batches_cls: int = 120\n",
        "\n",
        "    patience: int = 10\n",
        "    min_delta: float = 1e-4\n",
        "\n",
        "    amp: bool = True\n",
        "    resume: bool = True\n",
        "    resume_prefer_best: bool = True\n",
        "\n",
        "cfg = TrainConfig()\n",
        "seed_everything(cfg.seed)\n",
        "\n",
        "def make_split(dataset: Dataset, val_ratio: float, seed: int):\n",
        "    n = len(dataset)\n",
        "    n_val = int(round(n * val_ratio))\n",
        "    n_tr = n - n_val\n",
        "    g = torch.Generator().manual_seed(seed)\n",
        "    return random_split(dataset, [n_tr, n_val], generator=g)\n",
        "\n",
        "# =========================================================\n",
        "# Build datasets/loaders\n",
        "# =========================================================\n",
        "seg_all = ISICSegDataset(SEG_IMAGE_DIR, SEG_MASK_DIR, image_size=cfg.image_size)\n",
        "cls_all = ISICClsDataset(CLS_IMAGE_DIR, CLS_LABEL_CSV, image_size=cfg.image_size)\n",
        "\n",
        "seg_tr, seg_va = make_split(seg_all, cfg.val_ratio, cfg.seed)\n",
        "cls_tr, cls_va = make_split(cls_all, cfg.val_ratio, cfg.seed)\n",
        "\n",
        "common_loader_kwargs = dict(\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
        "    prefetch_factor=2 if cfg.num_workers > 0 else None\n",
        ")\n",
        "\n",
        "seg_train_loader = DataLoader(seg_tr, batch_size=cfg.batch_size, shuffle=True, **common_loader_kwargs)\n",
        "seg_val_loader   = DataLoader(seg_va, batch_size=1, shuffle=False, **common_loader_kwargs)\n",
        "\n",
        "cls_train_loader = DataLoader(cls_tr, batch_size=cfg.batch_size, shuffle=True, **common_loader_kwargs)\n",
        "cls_val_loader   = DataLoader(cls_va, batch_size=cfg.batch_size, shuffle=False, **common_loader_kwargs)\n",
        "\n",
        "# =========================================================\n",
        "# Model / Optim / AMP scaler (NEW API)\n",
        "# =========================================================\n",
        "model = HybridMTLModel(base_ch=32, num_classes=3, seg_dropout=0.10).to(cfg.device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
        "\n",
        "# ✅ NEW AMP API (no torch.cuda.amp)\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\")))\n",
        "\n",
        "# =========================================================\n",
        "# Checkpoint save/load\n",
        "# =========================================================\n",
        "def save_checkpoint(path: Path, model: nn.Module, optimizer, epoch: int, metrics: dict):\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n",
        "        \"metrics\": metrics,\n",
        "        \"time\": time.time(),\n",
        "        \"mm_per_pixel\": MM_PER_PIXEL,\n",
        "        \"field_size_mm\": FIELD_SIZE_MM,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "    }, str(path))\n",
        "\n",
        "def try_resume():\n",
        "    if not cfg.resume:\n",
        "        return 1, -1e18, -1\n",
        "\n",
        "    best_path = CHECKPOINT_DIR / \"best.pt\"\n",
        "    last_path = latest_epoch_ckpt(CHECKPOINT_DIR)\n",
        "    pick = None\n",
        "\n",
        "    if cfg.resume_prefer_best and best_path.exists():\n",
        "        pick = best_path\n",
        "    elif last_path is not None:\n",
        "        pick = last_path\n",
        "    elif best_path.exists():\n",
        "        pick = best_path\n",
        "\n",
        "    if pick is None:\n",
        "        print(\"[Resume] No checkpoint found. Start from epoch 1.\")\n",
        "        return 1, -1e18, -1\n",
        "\n",
        "    ckpt = torch.load(pick, map_location=cfg.device)\n",
        "    model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "    if ckpt.get(\"optimizer\") is not None:\n",
        "        try:\n",
        "            optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        except Exception as e:\n",
        "            print(\"[Resume] Optimizer state not loaded (ok). Reason:\", str(e))\n",
        "\n",
        "    start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "    best_score = float(ckpt.get(\"metrics\", {}).get(\"val_score\", -1e18))\n",
        "    best_epoch = int(ckpt.get(\"epoch\", -1))\n",
        "\n",
        "    print(f\"[Resume] Loaded: {pick.name} | start_epoch={start_epoch} | best_score={best_score:.4f} (ep{best_epoch})\")\n",
        "    return start_epoch, best_score, best_epoch\n",
        "\n",
        "# =========================================================\n",
        "# Train / Val\n",
        "# =========================================================\n",
        "def train_one_epoch(epoch: int):\n",
        "    model.train()\n",
        "    seg_iter = iter(seg_train_loader)\n",
        "    cls_iter = iter(cls_train_loader)\n",
        "\n",
        "    steps = cfg.steps_per_epoch\n",
        "    running = {\"loss\": 0.0, \"loss_seg\": 0.0, \"loss_cls\": 0.0}\n",
        "\n",
        "    pbar = tqdm(range(steps), desc=f\"[Train] Epoch {epoch}\", leave=False)\n",
        "    for i in pbar:\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # recycle iterators\n",
        "        try:\n",
        "            bseg = next(seg_iter)\n",
        "        except StopIteration:\n",
        "            seg_iter = iter(seg_train_loader)\n",
        "            bseg = next(seg_iter)\n",
        "\n",
        "        try:\n",
        "            bcls = next(cls_iter)\n",
        "        except StopIteration:\n",
        "            cls_iter = iter(cls_train_loader)\n",
        "            bcls = next(cls_iter)\n",
        "\n",
        "        # ✅ NEW autocast API\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "            # seg forward\n",
        "            x = bseg[\"image\"].to(cfg.device, non_blocking=True)\n",
        "            y = bseg[\"mask\"].to(cfg.device, non_blocking=True)\n",
        "            seg_logit, _ = model(x)\n",
        "            loss_seg = bce(seg_logit, y) + dice_loss_with_logits(seg_logit, y)\n",
        "\n",
        "            # cls forward\n",
        "            x2 = bcls[\"image\"].to(cfg.device, non_blocking=True)\n",
        "            y2 = bcls[\"label\"].to(cfg.device, non_blocking=True)\n",
        "            _, cls_logit = model(x2)\n",
        "            loss_cls = ce(cls_logit, y2)\n",
        "\n",
        "            loss = cfg.seg_w * loss_seg + cfg.cls_w * loss_cls\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running[\"loss\"] += float(loss.item())\n",
        "        running[\"loss_seg\"] += float(loss_seg.item())\n",
        "        running[\"loss_cls\"] += float(loss_cls.item())\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": running[\"loss\"]/(i+1),\n",
        "            \"seg\": running[\"loss_seg\"]/(i+1),\n",
        "            \"cls\": running[\"loss_cls\"]/(i+1),\n",
        "            \"lr\": scheduler.get_last_lr()[0]\n",
        "        })\n",
        "\n",
        "    scheduler.step()\n",
        "    return {k: v/steps for k, v in running.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_segmentation_mc(epoch: int, export_n: int = 2):\n",
        "    do_full = (epoch % cfg.mc_every == 0)\n",
        "    mc_T = cfg.mc_samples if do_full else cfg.mc_samples_fast\n",
        "\n",
        "    enable_dropout_only(model)\n",
        "\n",
        "    dices, bfs, hd95s_px = [], [], []\n",
        "    entropies, mis = [], []\n",
        "\n",
        "    export_dir = EXPORT_DIR / f\"epoch_{epoch:03d}\"\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for idx, b in enumerate(tqdm(seg_val_loader, desc=f\"[Val-Seg MC(T={mc_T})] Epoch {epoch}\", leave=False)):\n",
        "        if idx >= cfg.val_max_batches_seg:\n",
        "            break\n",
        "\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"mask\"].to(cfg.device)\n",
        "\n",
        "        mc_probs = []\n",
        "        for _ in range(mc_T):\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "                seg_logit, _ = model(x)\n",
        "                prob = torch.sigmoid(seg_logit).squeeze(0).squeeze(0)  # expected [H,W]\n",
        "            if prob.ndim != 2:\n",
        "                print(\"[WARN] prob shape unexpected:\", tuple(prob.shape), \"seg_logit:\", tuple(seg_logit.shape))\n",
        "                continue\n",
        "            mc_probs.append(prob.detach().float().cpu().numpy())\n",
        "\n",
        "        if len(mc_probs) == 0:\n",
        "            continue\n",
        "\n",
        "        mc_probs = np.stack(mc_probs, axis=0)  # [T,H,W]\n",
        "        p_lesion = mc_probs.mean(axis=0).astype(np.float32)\n",
        "        if p_lesion.ndim != 2:\n",
        "            print(\"[WARN] p_lesion shape unexpected:\", p_lesion.shape)\n",
        "            continue\n",
        "\n",
        "        pred_mask = (p_lesion > 0.5).astype(np.uint8)\n",
        "        gt_mask = (y.squeeze().detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        inter = (pred_mask & gt_mask).sum()\n",
        "        union = pred_mask.sum() + gt_mask.sum()\n",
        "        dice = (2 * inter / (union + 1e-6)) if union > 0 else 1.0\n",
        "        dices.append(float(dice))\n",
        "\n",
        "        bfs.append(bf_score(pred_mask, gt_mask, tol_px=2))\n",
        "        hd95s_px.append(hd95(pred_mask, gt_mask))\n",
        "\n",
        "        ent_map = predictive_entropy(p_lesion)\n",
        "        mi_map = mutual_information(mc_probs) if mc_T > 1 else np.zeros_like(ent_map)\n",
        "\n",
        "        entropies.append(float(ent_map.mean()))\n",
        "        mis.append(float(mi_map.mean()))\n",
        "\n",
        "        if do_full and idx < export_n:\n",
        "            p_boundary = compute_boundary_prob_from_plesion(p_lesion)\n",
        "            tw_mm = transition_width_map_mm(p_lesion)\n",
        "\n",
        "            np.save(export_dir / f\"val{idx:03d}_p_lesion.npy\", p_lesion)\n",
        "            np.save(export_dir / f\"val{idx:03d}_p_boundary.npy\", p_boundary)\n",
        "            np.save(export_dir / f\"val{idx:03d}_entropy.npy\", ent_map.astype(np.float32))\n",
        "            np.save(export_dir / f\"val{idx:03d}_mi.npy\", mi_map.astype(np.float32))\n",
        "            np.save(export_dir / f\"val{idx:03d}_transition_width_mm.npy\", tw_mm)\n",
        "\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_p_lesion.png\", p_lesion, \"p_lesion (mean prob)\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_p_boundary.png\", p_boundary, \"p_boundary (|∇p| normalized)\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_entropy.png\", ent_map, \"Predictive entropy\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_mi.png\", mi_map, \"Mutual information\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_transition_width_mm.png\", tw_mm, \"Transition width (mm)\")\n",
        "\n",
        "    val_dice = float(np.mean(dices)) if dices else 0.0\n",
        "    val_bf   = float(np.mean(bfs)) if bfs else 0.0\n",
        "    val_hd95_mm = float(np.mean(hd95s_px) * MM_PER_PIXEL) if hd95s_px else 0.0\n",
        "    mean_ent = float(np.mean(entropies)) if entropies else 0.0\n",
        "    mean_mi  = float(np.mean(mis)) if mis else 0.0\n",
        "\n",
        "    return {\n",
        "        \"val_dice\": val_dice,\n",
        "        \"val_bf\": val_bf,\n",
        "        \"val_hd95_mm\": val_hd95_mm,\n",
        "        \"val_pred_entropy_mean\": mean_ent,\n",
        "        \"val_mi_mean\": mean_mi,\n",
        "        \"mc_T\": mc_T,\n",
        "        \"mc_full\": bool(do_full),\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_classification(epoch: int):\n",
        "    model.eval()\n",
        "    all_logits, all_labels = [], []\n",
        "\n",
        "    for bi, b in enumerate(tqdm(cls_val_loader, desc=f\"[Val-Cls] Epoch {epoch}\", leave=False)):\n",
        "        if bi >= cfg.val_max_batches_cls:\n",
        "            break\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"label\"].to(cfg.device)\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "            _, logits = model(x)\n",
        "        all_logits.append(logits.detach().float().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "\n",
        "    if not all_logits:\n",
        "        return {\"val_acc\": 0.0, \"val_ece\": 0.0, \"val_aurc\": 0.0, \"val_nll\": 0.0, \"val_brier\": 0.0}\n",
        "\n",
        "    logits = np.concatenate(all_logits, axis=0)\n",
        "    labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    probs = softmax_np(logits)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    acc = float((pred == labels).mean())\n",
        "\n",
        "    ece = ece_score(probs, labels, n_bins=15)\n",
        "    nll = nll_score(probs, labels)\n",
        "    br  = brier_score(probs, labels)\n",
        "\n",
        "    unc = predictive_entropy(probs)\n",
        "    cov, risk = risk_coverage_curve(probs, labels, unc)\n",
        "    A = aurc(cov, risk)\n",
        "\n",
        "    export_dir = EXPORT_DIR / f\"epoch_{epoch:03d}\"\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    np.save(export_dir / \"risk_coverage_coverage.npy\", cov.astype(np.float32))\n",
        "    np.save(export_dir / \"risk_coverage_risk.npy\", risk.astype(np.float32))\n",
        "\n",
        "    plt.figure(figsize=(4, 3), dpi=150)\n",
        "    plt.plot(cov, risk)\n",
        "    plt.xlabel(\"Coverage\")\n",
        "    plt.ylabel(\"Risk (error rate)\")\n",
        "    plt.title(f\"Risk–Coverage (AURC={A:.4f})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(export_dir / \"risk_coverage_curve.png\", bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    return {\"val_acc\": acc, \"val_ece\": float(ece), \"val_aurc\": float(A), \"val_nll\": float(nll), \"val_brier\": float(br)}\n",
        "\n",
        "# =========================================================\n",
        "# Early stopping\n",
        "# =========================================================\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=10, min_delta=1e-4):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = -1e18\n",
        "        self.bad = 0\n",
        "    def step(self, score: float) -> bool:\n",
        "        if score > self.best + self.min_delta:\n",
        "            self.best = score\n",
        "            self.bad = 0\n",
        "            return False\n",
        "        self.bad += 1\n",
        "        return self.bad >= self.patience\n",
        "\n",
        "def composite_val_score(seg_m: dict, cls_m: dict) -> float:\n",
        "    dice = seg_m[\"val_dice\"]\n",
        "    bf = seg_m[\"val_bf\"]\n",
        "    hd = seg_m[\"val_hd95_mm\"]\n",
        "    acc = cls_m[\"val_acc\"]\n",
        "    ece = cls_m[\"val_ece\"]\n",
        "    aurc_v = cls_m[\"val_aurc\"]\n",
        "    nll = cls_m[\"val_nll\"]\n",
        "    brier = cls_m[\"val_brier\"]\n",
        "\n",
        "    score = (\n",
        "        2.0 * dice +\n",
        "        1.0 * bf +\n",
        "        1.0 * acc -\n",
        "        0.25 * math.log(1.0 + hd) -\n",
        "        0.5 * ece -\n",
        "        0.5 * aurc_v -\n",
        "        0.1 * nll -\n",
        "        0.1 * brier\n",
        "    )\n",
        "    return float(score)\n",
        "\n",
        "stopper = EarlyStopper(patience=cfg.patience, min_delta=cfg.min_delta)\n",
        "\n",
        "# =========================================================\n",
        "# Clear cache (safe if rerunning cells)\n",
        "# =========================================================\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# =========================================================\n",
        "# Resume\n",
        "# =========================================================\n",
        "start_epoch, best_score, best_epoch = try_resume()\n",
        "\n",
        "# If resumed from a later epoch, keep scheduler aligned (optional)\n",
        "# For cosine schedule, you can step scheduler to start_epoch-1:\n",
        "for _ in range(max(0, start_epoch - 1)):\n",
        "    scheduler.step()\n",
        "\n",
        "# =========================================================\n",
        "# Train loop\n",
        "# =========================================================\n",
        "for epoch in range(start_epoch, cfg.epochs + 1):\n",
        "    train_m = train_one_epoch(epoch)\n",
        "    seg_m = validate_segmentation_mc(epoch, export_n=2)\n",
        "    cls_m = validate_classification(epoch)\n",
        "\n",
        "    val_score = composite_val_score(seg_m, cls_m)\n",
        "\n",
        "    metrics = {**train_m, **seg_m, **cls_m,\n",
        "               \"val_score\": val_score,\n",
        "               \"epoch\": epoch,\n",
        "               \"mm_per_pixel\": MM_PER_PIXEL,\n",
        "               \"field_size_mm\": FIELD_SIZE_MM,\n",
        "               \"image_size\": IMAGE_SIZE,\n",
        "               \"amp\": cfg.amp,\n",
        "               \"steps_per_epoch\": cfg.steps_per_epoch}\n",
        "\n",
        "    # log\n",
        "    with open(CHECKPOINT_DIR.parent / \"train_log.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(pd.Series(metrics).to_json() + \"\\n\")\n",
        "\n",
        "    save_checkpoint(CHECKPOINT_DIR / f\"epoch_{epoch:03d}.pt\", model, optimizer, epoch, metrics)\n",
        "\n",
        "    if val_score > best_score:\n",
        "        best_score = val_score\n",
        "        best_epoch = epoch\n",
        "        save_checkpoint(CHECKPOINT_DIR / \"best.pt\", model, optimizer, epoch, metrics)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}] \"\n",
        "        f\"loss={train_m['loss']:.4f} | \"\n",
        "        f\"Dice={seg_m['val_dice']:.4f} BF={seg_m['val_bf']:.4f} HD95(mm)={seg_m['val_hd95_mm']:.3f} \"\n",
        "        f\"(MC T={seg_m['mc_T']}, full={seg_m['mc_full']}) | \"\n",
        "        f\"Acc={cls_m['val_acc']:.4f} ECE={cls_m['val_ece']:.4f} AURC={cls_m['val_aurc']:.4f} \"\n",
        "        f\"NLL={cls_m['val_nll']:.4f} Brier={cls_m['val_brier']:.4f} | \"\n",
        "        f\"val_score={val_score:.4f} best={best_score:.4f} (ep{best_epoch})\"\n",
        "    )\n",
        "\n",
        "    if stopper.step(val_score):\n",
        "        print(f\"Early stopping at epoch {epoch}. Best epoch={best_epoch}, best_score={best_score:.4f}\")\n",
        "        break\n",
        "\n",
        "print(f\"Training finished. Best epoch: {best_epoch}, best score: {best_score:.4f}\")\n",
        "print(f\"Exports saved to: {EXPORT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "2_zqzMa3WnKX",
        "outputId": "abe4e42c-dcd7-4b8b-b309-cfa054d68a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Resume] Loaded: best.pt | start_epoch=4 | best_score=2.2798 (ep3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 004] loss=0.6947 | Dice=0.8014 BF=0.3535 HD95(mm)=1.878 (MC T=2, full=False) | Acc=0.8187 ECE=0.0932 AURC=0.0585 NLL=0.5091 Brier=0.2846 | val_score=2.3556 best=2.3556 (ep4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 005] loss=0.6638 | Dice=0.8107 BF=0.3649 HD95(mm)=1.662 (MC T=8, full=True) | Acc=0.8208 ECE=0.0419 AURC=0.0514 NLL=0.4161 Brier=0.2490 | val_score=2.4491 best=2.4491 (ep5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 006] loss=0.6048 | Dice=0.8230 BF=0.3462 HD95(mm)=1.770 (MC T=2, full=False) | Acc=0.8156 ECE=0.0467 AURC=0.0510 NLL=0.4322 Brier=0.2571 | val_score=2.4354 best=2.4491 (ep5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 007] loss=0.5900 | Dice=0.7898 BF=0.3128 HD95(mm)=1.559 (MC T=2, full=False) | Acc=0.8271 ECE=0.0352 AURC=0.0524 NLL=0.4170 Brier=0.2456 | val_score=2.3744 best=2.4491 (ep5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 008] loss=0.5892 | Dice=0.7905 BF=0.2804 HD95(mm)=2.027 (MC T=2, full=False) | Acc=0.8271 ECE=0.0306 AURC=0.0489 NLL=0.4070 Brier=0.2434 | val_score=2.3067 best=2.4491 (ep5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 009] loss=0.5489 | Dice=0.8174 BF=0.3611 HD95(mm)=1.819 (MC T=2, full=False) | Acc=0.8146 ECE=0.0346 AURC=0.0494 NLL=0.4115 Brier=0.2470 | val_score=2.4435 best=2.4491 (ep5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 010] loss=0.5544 | Dice=0.8288 BF=0.3770 HD95(mm)=1.621 (MC T=8, full=True) | Acc=0.8219 ECE=0.0312 AURC=0.0461 NLL=0.3936 Brier=0.2396 | val_score=2.5137 best=2.5137 (ep10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 011] loss=0.5369 | Dice=0.8406 BF=0.4154 HD95(mm)=1.541 (MC T=2, full=False) | Acc=0.8240 ECE=0.0360 AURC=0.0450 NLL=0.4048 Brier=0.2356 | val_score=2.5828 best=2.5828 (ep11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 012] loss=0.5320 | Dice=0.8384 BF=0.4126 HD95(mm)=1.528 (MC T=2, full=False) | Acc=0.8333 ECE=0.0253 AURC=0.0458 NLL=0.3937 Brier=0.2381 | val_score=2.5921 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 013] loss=0.5109 | Dice=0.8190 BF=0.4067 HD95(mm)=1.576 (MC T=2, full=False) | Acc=0.8302 ECE=0.0613 AURC=0.0490 NLL=0.4551 Brier=0.2532 | val_score=2.5124 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 014] loss=0.5068 | Dice=0.8442 BF=0.3740 HD95(mm)=1.508 (MC T=2, full=False) | Acc=0.8313 ECE=0.0362 AURC=0.0478 NLL=0.4089 Brier=0.2403 | val_score=2.5569 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 015] loss=0.5010 | Dice=0.8448 BF=0.3805 HD95(mm)=1.428 (MC T=8, full=True) | Acc=0.8510 ECE=0.0527 AURC=0.0404 NLL=0.3886 Brier=0.2230 | val_score=2.5917 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 016] loss=0.4871 | Dice=0.8305 BF=0.3768 HD95(mm)=1.540 (MC T=2, full=False) | Acc=0.8458 ECE=0.0412 AURC=0.0426 NLL=0.3885 Brier=0.2293 | val_score=2.5470 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 017] loss=0.4731 | Dice=0.8444 BF=0.4054 HD95(mm)=1.467 (MC T=2, full=False) | Acc=0.7979 ECE=0.0393 AURC=0.0527 NLL=0.4263 Brier=0.2493 | val_score=2.5528 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 018] loss=0.4696 | Dice=0.8257 BF=0.4114 HD95(mm)=1.639 (MC T=2, full=False) | Acc=0.8417 ECE=0.0274 AURC=0.0437 NLL=0.3860 Brier=0.2272 | val_score=2.5651 best=2.5921 (ep12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 019] loss=0.4697 | Dice=0.8415 BF=0.4132 HD95(mm)=1.545 (MC T=2, full=False) | Acc=0.8417 ECE=0.0398 AURC=0.0437 NLL=0.3892 Brier=0.2249 | val_score=2.6012 best=2.6012 (ep19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 020] loss=0.4648 | Dice=0.8497 BF=0.4196 HD95(mm)=1.354 (MC T=8, full=True) | Acc=0.8344 ECE=0.0217 AURC=0.0426 NLL=0.3751 Brier=0.2227 | val_score=2.6474 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 021] loss=0.4512 | Dice=0.8582 BF=0.4124 HD95(mm)=1.337 (MC T=2, full=False) | Acc=0.8385 ECE=0.0432 AURC=0.0460 NLL=0.4023 Brier=0.2309 | val_score=2.6472 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 022] loss=0.4438 | Dice=0.8377 BF=0.3584 HD95(mm)=1.545 (MC T=2, full=False) | Acc=0.8406 ECE=0.0368 AURC=0.0436 NLL=0.3850 Brier=0.2280 | val_score=2.5395 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 023] loss=0.4421 | Dice=0.8381 BF=0.3712 HD95(mm)=1.537 (MC T=2, full=False) | Acc=0.8542 ECE=0.0344 AURC=0.0382 NLL=0.3672 Brier=0.2079 | val_score=2.5751 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 024] loss=0.4291 | Dice=0.8398 BF=0.3562 HD95(mm)=1.436 (MC T=2, full=False) | Acc=0.8583 ECE=0.0431 AURC=0.0356 NLL=0.3622 Brier=0.2029 | val_score=2.5755 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 025] loss=0.4234 | Dice=0.8428 BF=0.4052 HD95(mm)=1.369 (MC T=8, full=True) | Acc=0.8292 ECE=0.0294 AURC=0.0415 NLL=0.3832 Brier=0.2278 | val_score=2.6079 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 026] loss=0.4238 | Dice=0.8448 BF=0.4137 HD95(mm)=1.364 (MC T=2, full=False) | Acc=0.8333 ECE=0.0245 AURC=0.0430 NLL=0.3817 Brier=0.2274 | val_score=2.6268 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 027] loss=0.4131 | Dice=0.8477 BF=0.4045 HD95(mm)=1.487 (MC T=2, full=False) | Acc=0.8479 ECE=0.0375 AURC=0.0395 NLL=0.3799 Brier=0.2155 | val_score=2.6220 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 028] loss=0.3991 | Dice=0.8338 BF=0.4297 HD95(mm)=1.449 (MC T=2, full=False) | Acc=0.8281 ECE=0.0354 AURC=0.0432 NLL=0.3885 Brier=0.2258 | val_score=2.6007 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 029] loss=0.3922 | Dice=0.8323 BF=0.4045 HD95(mm)=1.373 (MC T=2, full=False) | Acc=0.8531 ECE=0.0386 AURC=0.0365 NLL=0.3485 Brier=0.2001 | val_score=2.6137 best=2.6474 (ep20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 030] loss=0.3872 | Dice=0.8589 BF=0.4208 HD95(mm)=1.318 (MC T=8, full=True) | Acc=0.8490 ECE=0.0302 AURC=0.0378 NLL=0.3710 Brier=0.2075 | val_score=2.6856 best=2.6856 (ep30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 031] loss=0.3688 | Dice=0.8474 BF=0.3973 HD95(mm)=1.442 (MC T=2, full=False) | Acc=0.8490 ECE=0.0601 AURC=0.0407 NLL=0.4014 Brier=0.2224 | val_score=2.6051 best=2.6856 (ep30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 032] loss=0.3849 | Dice=0.8617 BF=0.3920 HD95(mm)=1.317 (MC T=2, full=False) | Acc=0.8344 ECE=0.0429 AURC=0.0410 NLL=0.3785 Brier=0.2224 | val_score=2.6376 best=2.6856 (ep30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 033] loss=0.3709 | Dice=0.8356 BF=0.4013 HD95(mm)=1.543 (MC T=2, full=False) | Acc=0.8469 ECE=0.0544 AURC=0.0392 NLL=0.3992 Brier=0.2174 | val_score=2.5775 best=2.6856 (ep30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1542629866.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;31m# =========================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m     \u001b[0mtrain_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0mseg_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_segmentation_mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0mcls_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1542629866.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# recycle iterators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mbseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mseg_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\".strip())\n",
        "\n",
        "if CLS_LABEL_CSV.exists():\n",
        "    print(f\"The file {CLS_LABEL_CSV.name} exists at: {CLS_LABEL_CSV}\")\n",
        "else:\n",
        "    print(f\"Error: The file {CLS_LABEL_CSV.name} does NOT exist at: {CLS_LABEL_CSV}\")\n",
        "    print(\"Please check the path and filename.\")\n",
        "\n",
        "# The rest of the original code should follow here\n",
        "# ... (original content of the cell should be appended here)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oixKFofbRCP",
        "outputId": "1ea395b1-40f9-47c6-8dd4-364be1c76984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file ISIC2018_Task3_Training_GroundTruth.csv exists at: /content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_Input\".strip())\n",
        "\n",
        "if CLS_LABEL_CSV.exists():\n",
        "    print(f\"The file {CLS_LABEL_CSV.name} exists at: {CLS_LABEL_CSV}\")\n",
        "else:\n",
        "    print(f\"Error: The file {CLS_LABEL_CSV.name} does NOT exist at: {CLS_LABEL_CSV}\")\n",
        "    print(\"Please check the path and filename.\")\n",
        "\n",
        "# The rest of the original code should follow here\n",
        "# ... (original content of the cell should be appended here)"
      ],
      "metadata": {
        "id": "ckptr6YT7J1K",
        "outputId": "c7dda804-e59d-489d-f867-896c1d7de130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file ISIC2018_Task3_Training_Input exists at: /content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_Input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/isic2018/images\".strip())\n",
        "\n",
        "if CLS_LABEL_CSV.exists():\n",
        "    print(f\"The file {CLS_LABEL_CSV.name} exists at: {CLS_LABEL_CSV}\")\n",
        "else:\n",
        "    print(f\"Error: The file {CLS_LABEL_CSV.name} does NOT exist at: {CLS_LABEL_CSV}\")\n",
        "    print(\"Please check the path and filename.\")\n",
        "\n",
        "# The rest of the original code should follow here\n",
        "# ... (original content of the cell should be appended here)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMN10Lni8nHw",
        "outputId": "7373f58e-a67e-497c-8a27-dc710ab48db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file images exists at: /content/drive/My Drive/isic2018/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWF8u5nY-Sq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "id": "5m6dgMc89cPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Hybrid CNN–ViT–U-Net (Seg + Cls) with NEW AMP API + resume + finetune\n",
        "# ISIC 2018 Task 1 (Seg) + Task 3 (Cls)\n",
        "# Physical size: 15mm × 15mm → 256 × 256 px\n",
        "#\n",
        "# Fine-tune:\n",
        "# - LR ↓ (e.g., 3e-4 -> 1e-4 or 5e-5)\n",
        "# - cls_w ↓ (e.g., 0.5 -> 0.3)\n",
        "# - classification loss: weighted CE OR focal\n",
        "#\n",
        "# Fix scheduler warning:\n",
        "# - save scheduler into checkpoint\n",
        "# - load scheduler when resume\n",
        "# - NO manual scheduler.step() loop on resume\n",
        "# =========================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import time, math, random, gc, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "# =========================================================\n",
        "# Performance settings\n",
        "# =========================================================\n",
        "cv2.setNumThreads(0)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "# =========================================================\n",
        "# Paths\n",
        "# =========================================================\n",
        "SEG_IMAGE_DIR = Path(\"/content/drive/My Drive/isic2018/images\")\n",
        "SEG_MASK_DIR  = Path(\"/content/drive/My Drive/isic2018/masks\")\n",
        "\n",
        "CLS_IMAGE_DIR = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_Input\".strip())\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\".strip())\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"/content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/checkpoints\".strip())\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "EXPORT_DIR = CHECKPOINT_DIR.parent / \"exports\"\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# =========================================================\n",
        "# Physical size definition\n",
        "# =========================================================\n",
        "FIELD_SIZE_MM = 15.0\n",
        "IMAGE_SIZE = 256\n",
        "MM_PER_PIXEL = FIELD_SIZE_MM / IMAGE_SIZE\n",
        "\n",
        "# =========================================================\n",
        "# Utils\n",
        "# =========================================================\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def save_map_with_mm_axis(path_png: Path, arr: np.ndarray, title: str):\n",
        "    arr = np.asarray(arr)\n",
        "    if arr.ndim == 1:\n",
        "        if arr.size == IMAGE_SIZE * IMAGE_SIZE:\n",
        "            arr = arr.reshape(IMAGE_SIZE, IMAGE_SIZE)\n",
        "        else:\n",
        "            x_mm = np.linspace(0, FIELD_SIZE_MM, arr.size)\n",
        "            plt.figure(figsize=(5, 3), dpi=150)\n",
        "            plt.plot(x_mm, arr)\n",
        "            plt.xlabel(\"x (mm)\")\n",
        "            plt.ylabel(\"value\")\n",
        "            plt.title(title + f\" (1D, shape={arr.shape})\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(path_png, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "            return\n",
        "    if arr.ndim != 2:\n",
        "        print(f\"[WARN] Skip saving {title}: invalid shape={arr.shape}\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(5, 4), dpi=150)\n",
        "    plt.imshow(arr, extent=(0, FIELD_SIZE_MM, FIELD_SIZE_MM, 0))\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    plt.xlabel(\"x (mm)\")\n",
        "    plt.ylabel(\"y (mm)\")\n",
        "    plt.title(title + f\" (shape={arr.shape})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path_png, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def latest_epoch_ckpt(ckpt_dir: Path) -> Path | None:\n",
        "    pts = sorted(ckpt_dir.glob(\"epoch_*.pt\"))\n",
        "    if not pts:\n",
        "        return None\n",
        "    def key(p: Path):\n",
        "        m = re.search(r\"epoch_(\\d+)\\.pt$\", p.name)\n",
        "        return int(m.group(1)) if m else -1\n",
        "    pts = sorted(pts, key=key)\n",
        "    return pts[-1] if key(pts[-1]) >= 0 else None\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Segmentation (ISIC 2018 Task 1)\n",
        "# =========================================================\n",
        "class ISICSegDataset(Dataset):\n",
        "    def __init__(self, image_dir: Path, mask_dir: Path, image_size: int = 256):\n",
        "        self.image_paths = sorted(image_dir.glob(\"*.jpg\"))\n",
        "        self.mask_paths = [mask_dir / f\"{p.stem}_segmentation.png\" for p in self.image_paths]\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Cannot read mask: {mask_path}\")\n",
        "\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1)     # [3,H,W]\n",
        "        mask = torch.from_numpy(mask).unsqueeze(0)       # [1,H,W]\n",
        "        return {\"image\": img, \"mask\": mask}\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Classification (ISIC 2018 Task 3) supports one-hot CSV\n",
        "# =========================================================\n",
        "CLS_MAP_DX = {\n",
        "    \"MEL\": 2, \"BCC\": 2,\n",
        "    \"AKIEC\": 1,\n",
        "    \"NV\": 0, \"BKL\": 0, \"DF\": 0, \"VASC\": 0\n",
        "}\n",
        "\n",
        "class ISICClsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A) one-hot CSV:\n",
        "       columns: image, MEL, NV, BCC, AKIEC, BKL, DF, VASC\n",
        "    B) dx CSV:\n",
        "       columns: image_id, dx\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir: Path, label_csv: Path, image_size: int = 256):\n",
        "        self.image_dir = image_dir\n",
        "        self.df = pd.read_csv(label_csv)\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.df.columns = self.df.columns.str.strip()\n",
        "        cols = set(self.df.columns)\n",
        "\n",
        "        onehot_classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "        has_onehot = (\"image\" in cols) and all(c in cols for c in onehot_classes)\n",
        "        has_dx = (\"image_id\" in cols and \"dx\" in cols)\n",
        "\n",
        "        if not (has_onehot or has_dx):\n",
        "            raise ValueError(\n",
        "                \"Unsupported CSV columns. Expect either:\\n\"\n",
        "                \"A) one-hot: image + MEL,NV,BCC,AKIEC,BKL,DF,VASC\\n\"\n",
        "                \"or B) dx: image_id + dx\\n\"\n",
        "                f\"Got columns: {list(self.df.columns)}\"\n",
        "            )\n",
        "\n",
        "        self.records = []\n",
        "        if has_onehot:\n",
        "            for _, row in self.df.iterrows():\n",
        "                img_id = str(row[\"image\"]).strip()\n",
        "                malignant = (row[\"MEL\"] == 1) or (row[\"BCC\"] == 1)\n",
        "                intermediate = (row[\"AKIEC\"] == 1)\n",
        "                benign = (row[\"NV\"] == 1) or (row[\"BKL\"] == 1) or (row[\"DF\"] == 1) or (row[\"VASC\"] == 1)\n",
        "\n",
        "                if malignant:\n",
        "                    label = 2\n",
        "                elif intermediate:\n",
        "                    label = 1\n",
        "                elif benign:\n",
        "                    label = 0\n",
        "                else:\n",
        "                    continue\n",
        "                self.records.append((img_id, label))\n",
        "        else:\n",
        "            for _, row in self.df.iterrows():\n",
        "                dx = str(row[\"dx\"]).strip()\n",
        "                if dx not in CLS_MAP_DX:\n",
        "                    continue\n",
        "                img_id = str(row[\"image_id\"]).strip()\n",
        "                self.records.append((img_id, CLS_MAP_DX[dx]))\n",
        "\n",
        "        if len(self.records) == 0:\n",
        "            raise ValueError(\"No valid records parsed from CSV. Check labels/image ids.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id, label = self.records[idx]\n",
        "        img_path = self.image_dir / f\"{img_id}.jpg\"\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            img_path2 = self.image_dir / f\"{img_id}.png\"\n",
        "            img = cv2.imread(str(img_path2))\n",
        "            if img is None:\n",
        "                raise FileNotFoundError(f\"Cannot find image for id={img_id}: {img_path} or {img_path2}\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        return {\"image\": img, \"label\": torch.tensor(label, dtype=torch.long)}\n",
        "\n",
        "# =========================================================\n",
        "# Model blocks\n",
        "# =========================================================\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GELU()\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(ConvBNAct(in_ch, out_ch), ConvBNAct(out_ch, out_ch))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=32):\n",
        "        super().__init__()\n",
        "        self.e1 = ConvBlock(in_ch, base_ch)            # H\n",
        "        self.e2 = ConvBlock(base_ch, base_ch * 2)      # H/2\n",
        "        self.e3 = ConvBlock(base_ch * 2, base_ch * 4)  # H/4\n",
        "        self.e4 = ConvBlock(base_ch * 4, base_ch * 8)  # H/8\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "    def forward(self, x):\n",
        "        f1 = self.e1(x)\n",
        "        f2 = self.e2(self.pool(f1))\n",
        "        f3 = self.e3(self.pool(f2))\n",
        "        f4 = self.e4(self.pool(f3))\n",
        "        return [f1, f2, f3, f4]\n",
        "\n",
        "class ViTBottleneck(nn.Module):\n",
        "    def __init__(self, dim, depth=2, heads=4, drop=0.1):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=dim, nhead=heads, dim_feedforward=dim*4,\n",
        "            dropout=drop, activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, depth)\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        tokens = x.flatten(2).transpose(1, 2)  # [B,N,C]\n",
        "        tokens = self.encoder(tokens)\n",
        "        return tokens.transpose(1, 2).reshape(b, c, h, w)\n",
        "\n",
        "class UNetDecoder(nn.Module):\n",
        "    def __init__(self, base_ch=32, out_ch=1, dropout_p=0.10):\n",
        "        super().__init__()\n",
        "        self.up3 = nn.ConvTranspose2d(base_ch*8, base_ch*4, 2, 2)\n",
        "        self.d3  = ConvBlock(base_ch*8, base_ch*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base_ch*4, base_ch*2, 2, 2)\n",
        "        self.d2  = ConvBlock(base_ch*4, base_ch*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_ch*2, base_ch, 2, 2)\n",
        "        self.d1  = ConvBlock(base_ch*2, base_ch)\n",
        "        self.drop = nn.Dropout2d(dropout_p) if dropout_p > 0 else nn.Identity()\n",
        "        self.out  = nn.Conv2d(base_ch, out_ch, 1)\n",
        "    def forward(self, feats):\n",
        "        f1, f2, f3, f4 = feats\n",
        "        x = self.up3(f4)\n",
        "        x = self.d3(torch.cat([x, f3], dim=1))\n",
        "        x = self.up2(x)\n",
        "        x = self.d2(torch.cat([x, f2], dim=1))\n",
        "        x = self.up1(x)\n",
        "        x = self.d1(torch.cat([x, f1], dim=1))\n",
        "        x = self.drop(x)\n",
        "        return self.out(x)\n",
        "\n",
        "class HybridMTLModel(nn.Module):\n",
        "    def __init__(self, base_ch=32, num_classes=3, seg_dropout=0.10):\n",
        "        super().__init__()\n",
        "        self.encoder = ConvEncoder(3, base_ch)\n",
        "        self.bottleneck = ViTBottleneck(base_ch*8, depth=2, heads=4, drop=0.1)\n",
        "        self.decoder = UNetDecoder(base_ch, out_ch=1, dropout_p=seg_dropout)\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base_ch*8, base_ch*8),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(base_ch*8, num_classes),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x)\n",
        "        feats[-1] = self.bottleneck(feats[-1])\n",
        "        seg_logit = self.decoder(feats)\n",
        "        cls_logit = self.cls_head(feats[-1])\n",
        "        return seg_logit, cls_logit\n",
        "\n",
        "# =========================================================\n",
        "# Metrics (seg)\n",
        "# =========================================================\n",
        "def mask_to_boundary(mask: np.ndarray) -> np.ndarray:\n",
        "    mask_u8 = (mask > 0).astype(np.uint8)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    er = cv2.erode(mask_u8, kernel, iterations=1)\n",
        "    bd = (mask_u8 - er) > 0\n",
        "    return bd.astype(np.uint8)\n",
        "\n",
        "def bf_score(pred_mask: np.ndarray, gt_mask: np.ndarray, tol_px: int = 2) -> float:\n",
        "    pb = mask_to_boundary(pred_mask)\n",
        "    gb = mask_to_boundary(gt_mask)\n",
        "    if pb.sum() == 0 and gb.sum() == 0:\n",
        "        return 1.0\n",
        "    if pb.sum() == 0 or gb.sum() == 0:\n",
        "        return 0.0\n",
        "    dt_g = ndi.distance_transform_edt(1 - gb)\n",
        "    dt_p = ndi.distance_transform_edt(1 - pb)\n",
        "    prec = (dt_g[pb.astype(bool)] <= tol_px).mean() if pb.sum() > 0 else 0.0\n",
        "    rec  = (dt_p[gb.astype(bool)] <= tol_px).mean() if gb.sum() > 0 else 0.0\n",
        "    return float(2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "\n",
        "def hd95(pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:\n",
        "    pb = mask_to_boundary(pred_mask).astype(bool)\n",
        "    gb = mask_to_boundary(gt_mask).astype(bool)\n",
        "    if pb.sum() == 0 and gb.sum() == 0:\n",
        "        return 0.0\n",
        "    if pb.sum() == 0 or gb.sum() == 0:\n",
        "        h, w = pred_mask.shape\n",
        "        return float(math.sqrt(h*h + w*w))\n",
        "    dt_g = ndi.distance_transform_edt(~gb)\n",
        "    dt_p = ndi.distance_transform_edt(~pb)\n",
        "    d1 = dt_g[pb]\n",
        "    d2 = dt_p[gb]\n",
        "    all_d = np.concatenate([d1, d2], axis=0)\n",
        "    return float(np.percentile(all_d, 95))\n",
        "\n",
        "# =========================================================\n",
        "# Metrics (cls)\n",
        "# =========================================================\n",
        "def softmax_np(logits: np.ndarray) -> np.ndarray:\n",
        "    x = logits - logits.max(axis=1, keepdims=True)\n",
        "    e = np.exp(x)\n",
        "    return e / (e.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def ece_score(probs: np.ndarray, labels: np.ndarray, n_bins: int = 15) -> float:\n",
        "    conf = probs.max(axis=1)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    acc = (pred == labels).astype(np.float32)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        m = (conf > bins[i]) & (conf <= bins[i+1])\n",
        "        if m.any():\n",
        "            ece += abs(acc[m].mean() - conf[m].mean()) * m.mean()\n",
        "    return float(ece)\n",
        "\n",
        "def nll_score(probs: np.ndarray, labels: np.ndarray) -> float:\n",
        "    p = probs[np.arange(len(labels)), labels]\n",
        "    return float((-np.log(p + 1e-12)).mean())\n",
        "\n",
        "def brier_score(probs: np.ndarray, labels: np.ndarray) -> float:\n",
        "    n, k = probs.shape\n",
        "    y = np.zeros((n, k), dtype=np.float32)\n",
        "    y[np.arange(n), labels] = 1.0\n",
        "    return float(((probs - y) ** 2).sum(axis=1).mean())\n",
        "\n",
        "def predictive_entropy(p: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    if p.ndim >= 2 and p.shape[-1] > 1:\n",
        "        return -(p * np.log(p + eps)).sum(axis=-1)\n",
        "    return -(p*np.log(p+eps) + (1-p)*np.log(1-p+eps))\n",
        "\n",
        "def risk_coverage_curve(probs: np.ndarray, labels: np.ndarray, uncertainty: np.ndarray):\n",
        "    n = len(labels)\n",
        "    order = np.argsort(uncertainty)\n",
        "    probs_s = probs[order]\n",
        "    labels_s = labels[order]\n",
        "    pred = probs_s.argmax(axis=1)\n",
        "    err = (pred != labels_s).astype(np.float32)\n",
        "    coverages = np.linspace(1/n, 1.0, n)\n",
        "    risks = np.cumsum(err) / (np.arange(n) + 1)\n",
        "    return coverages, risks\n",
        "\n",
        "def aurc(coverages: np.ndarray, risks: np.ndarray) -> float:\n",
        "    return float(np.trapezoid(risks, coverages))\n",
        "\n",
        "# =========================================================\n",
        "# MC Dropout helpers (seg)\n",
        "# =========================================================\n",
        "def enable_dropout_only(model: nn.Module):\n",
        "    model.eval()\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
        "            m.train()\n",
        "\n",
        "def mutual_information(mc_probs: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    mean_p = mc_probs.mean(axis=0)\n",
        "    H_mean = predictive_entropy(mean_p, eps=eps)\n",
        "    H_each = predictive_entropy(mc_probs, eps=eps)\n",
        "    return H_mean - H_each.mean(axis=0)\n",
        "\n",
        "def compute_boundary_prob_from_plesion(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy)\n",
        "    g = g / (g.max() + 1e-12)\n",
        "    return g.astype(np.float32)\n",
        "\n",
        "def transition_width_map_mm(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy) + 1e-12\n",
        "    width_px = 0.6 / g\n",
        "    width_mm = width_px * MM_PER_PIXEL\n",
        "    return np.clip(width_mm, 0.0, 10.0).astype(np.float32)\n",
        "\n",
        "# =========================================================\n",
        "# Losses (Seg + Cls)\n",
        "# =========================================================\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def dice_loss_with_logits(logits, targets, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    num = 2 * (probs * targets).sum(dim=(2, 3))\n",
        "    den = (probs + targets).sum(dim=(2, 3)) + eps\n",
        "    return (1 - (num / den)).mean()\n",
        "\n",
        "def compute_class_weights_from_loader(loader: DataLoader, device: str, num_classes: int = 3):\n",
        "    counts = np.zeros((num_classes,), dtype=np.int64)\n",
        "    for b in loader:\n",
        "        y = b[\"label\"].numpy()\n",
        "        for c in range(num_classes):\n",
        "            counts[c] += (y == c).sum()\n",
        "    counts = np.maximum(counts, 1)\n",
        "    inv = 1.0 / counts.astype(np.float32)\n",
        "    w = inv / inv.sum() * num_classes\n",
        "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Multi-class focal loss.\"\"\"\n",
        "    def __init__(self, gamma: float = 2.0, alpha: torch.Tensor | None = None, reduction: str = \"mean\"):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha  # tensor shape [C] or None\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor):\n",
        "        logp = torch.log_softmax(logits, dim=1)                  # [B,C]\n",
        "        p = torch.exp(logp)                                      # [B,C]\n",
        "        pt = p.gather(1, targets.view(-1, 1)).squeeze(1)         # [B]\n",
        "        logpt = logp.gather(1, targets.view(-1, 1)).squeeze(1)   # [B]\n",
        "        loss = -((1 - pt) ** self.gamma) * logpt\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha.gather(0, targets)\n",
        "            loss = loss * at\n",
        "\n",
        "        if self.reduction == \"mean\":\n",
        "            return loss.mean()\n",
        "        if self.reduction == \"sum\":\n",
        "            return loss.sum()\n",
        "        return loss\n",
        "\n",
        "# =========================================================\n",
        "# Config\n",
        "# =========================================================\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    image_size: int = 256\n",
        "    batch_size: int = 8\n",
        "    epochs: int = 60\n",
        "\n",
        "    # base lr (pretrain stage)\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-2\n",
        "\n",
        "    num_workers: int = 2\n",
        "    grad_clip: float = 1.0\n",
        "    val_ratio: float = 0.15\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    amp: bool = True\n",
        "\n",
        "    # task weights\n",
        "    seg_w: float = 1.0\n",
        "    cls_w: float = 0.5\n",
        "\n",
        "    # speed controls\n",
        "    steps_per_epoch: int = 350\n",
        "    mc_samples: int = 8\n",
        "    mc_samples_fast: int = 2\n",
        "    mc_every: int = 5\n",
        "    val_max_batches_seg: int = 120\n",
        "    val_max_batches_cls: int = 120\n",
        "\n",
        "    # early stopping\n",
        "    patience: int = 10\n",
        "    min_delta: float = 1e-4\n",
        "\n",
        "    # resume\n",
        "    resume: bool = True\n",
        "    resume_prefer_best: bool = True\n",
        "\n",
        "    # ---- fine-tune switch ----\n",
        "    finetune: bool = True\n",
        "    finetune_lr: float = 1e-4       # ✅ LR 降一档（也可 5e-5）\n",
        "    finetune_cls_w: float = 0.30    # ✅ cls_w 降一点\n",
        "\n",
        "    # ---- classification loss choice ----\n",
        "    # \"weighted_ce\" or \"focal\"\n",
        "    cls_loss: str = \"focal\"\n",
        "    focal_gamma: float = 2.0\n",
        "\n",
        "cfg = TrainConfig()\n",
        "seed_everything(cfg.seed)\n",
        "\n",
        "# =========================================================\n",
        "# Split helper\n",
        "# =========================================================\n",
        "def make_split(dataset: Dataset, val_ratio: float, seed: int):\n",
        "    n = len(dataset)\n",
        "    n_val = int(round(n * val_ratio))\n",
        "    n_tr = n - n_val\n",
        "    g = torch.Generator().manual_seed(seed)\n",
        "    return random_split(dataset, [n_tr, n_val], generator=g)\n",
        "\n",
        "# =========================================================\n",
        "# Build datasets/loaders\n",
        "# =========================================================\n",
        "seg_all = ISICSegDataset(SEG_IMAGE_DIR, SEG_MASK_DIR, image_size=cfg.image_size)\n",
        "cls_all = ISICClsDataset(CLS_IMAGE_DIR, CLS_LABEL_CSV, image_size=cfg.image_size)\n",
        "\n",
        "seg_tr, seg_va = make_split(seg_all, cfg.val_ratio, cfg.seed)\n",
        "cls_tr, cls_va = make_split(cls_all, cfg.val_ratio, cfg.seed)\n",
        "\n",
        "common_loader_kwargs = dict(\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True if cfg.num_workers > 0 else False,\n",
        "    prefetch_factor=2 if cfg.num_workers > 0 else None\n",
        ")\n",
        "\n",
        "seg_train_loader = DataLoader(seg_tr, batch_size=cfg.batch_size, shuffle=True, **common_loader_kwargs)\n",
        "seg_val_loader   = DataLoader(seg_va, batch_size=1, shuffle=False, **common_loader_kwargs)\n",
        "\n",
        "cls_train_loader = DataLoader(cls_tr, batch_size=cfg.batch_size, shuffle=True, **common_loader_kwargs)\n",
        "cls_val_loader   = DataLoader(cls_va, batch_size=cfg.batch_size, shuffle=False, **common_loader_kwargs)\n",
        "\n",
        "# =========================================================\n",
        "# Model / Optim / Scheduler / AMP scaler\n",
        "# =========================================================\n",
        "model = HybridMTLModel(base_ch=32, num_classes=3, seg_dropout=0.10).to(cfg.device)\n",
        "\n",
        "# --- classification weights from training set ---\n",
        "cls_weights = compute_class_weights_from_loader(cls_train_loader, cfg.device, num_classes=3)\n",
        "\n",
        "# --- choose classification loss ---\n",
        "if cfg.cls_loss.lower() == \"weighted_ce\":\n",
        "    cls_criterion = nn.CrossEntropyLoss(weight=cls_weights)\n",
        "elif cfg.cls_loss.lower() == \"focal\":\n",
        "    cls_criterion = FocalLoss(gamma=cfg.focal_gamma, alpha=cls_weights, reduction=\"mean\")\n",
        "else:\n",
        "    raise ValueError(\"cfg.cls_loss must be 'weighted_ce' or 'focal'\")\n",
        "\n",
        "# --- optimizer / scheduler ---\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
        "\n",
        "# --- NEW AMP API ---\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\")))\n",
        "\n",
        "# =========================================================\n",
        "# Checkpoint save/load (SAVE scheduler + LOAD scheduler)\n",
        "# =========================================================\n",
        "def save_checkpoint(path: Path, model: nn.Module, optimizer, scheduler, epoch: int, metrics: dict):\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict() if optimizer is not None else None,\n",
        "        \"scheduler\": scheduler.state_dict() if scheduler is not None else None,\n",
        "        \"metrics\": metrics,\n",
        "        \"time\": time.time(),\n",
        "        \"mm_per_pixel\": MM_PER_PIXEL,\n",
        "        \"field_size_mm\": FIELD_SIZE_MM,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "        \"cfg\": vars(cfg),\n",
        "    }, str(path))\n",
        "\n",
        "def try_resume():\n",
        "    if not cfg.resume:\n",
        "        return 1, -1e18, -1\n",
        "\n",
        "    best_path = CHECKPOINT_DIR / \"best.pt\"\n",
        "    last_path = latest_epoch_ckpt(CHECKPOINT_DIR)\n",
        "    pick = None\n",
        "\n",
        "    if cfg.resume_prefer_best and best_path.exists():\n",
        "        pick = best_path\n",
        "    elif last_path is not None:\n",
        "        pick = last_path\n",
        "    elif best_path.exists():\n",
        "        pick = best_path\n",
        "\n",
        "    if pick is None:\n",
        "        print(\"[Resume] No checkpoint found. Start from epoch 1.\")\n",
        "        return 1, -1e18, -1\n",
        "\n",
        "    ckpt = torch.load(pick, map_location=cfg.device)\n",
        "    model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "\n",
        "    if ckpt.get(\"optimizer\") is not None:\n",
        "        try:\n",
        "            optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        except Exception as e:\n",
        "            print(\"[Resume] Optimizer state not loaded (ok). Reason:\", str(e))\n",
        "\n",
        "    # ✅ load scheduler state (fix warning)\n",
        "    if ckpt.get(\"scheduler\") is not None:\n",
        "        try:\n",
        "            scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "        except Exception as e:\n",
        "            print(\"[Resume] Scheduler state not loaded (ok). Reason:\", str(e))\n",
        "\n",
        "    start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "    best_score = float(ckpt.get(\"metrics\", {}).get(\"val_score\", -1e18))\n",
        "    best_epoch = int(ckpt.get(\"epoch\", -1))\n",
        "\n",
        "    print(f\"[Resume] Loaded: {pick.name} | start_epoch={start_epoch} | best_score={best_score:.4f} (ep{best_epoch})\")\n",
        "    return start_epoch, best_score, best_epoch\n",
        "\n",
        "# =========================================================\n",
        "# Train / Val\n",
        "# =========================================================\n",
        "def train_one_epoch(epoch: int):\n",
        "    model.train()\n",
        "    seg_iter = iter(seg_train_loader)\n",
        "    cls_iter = iter(cls_train_loader)\n",
        "\n",
        "    steps = cfg.steps_per_epoch\n",
        "    running = {\"loss\": 0.0, \"loss_seg\": 0.0, \"loss_cls\": 0.0}\n",
        "\n",
        "    pbar = tqdm(range(steps), desc=f\"[Train] Epoch {epoch}\", leave=False)\n",
        "    for i in pbar:\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        try:\n",
        "            bseg = next(seg_iter)\n",
        "        except StopIteration:\n",
        "            seg_iter = iter(seg_train_loader)\n",
        "            bseg = next(seg_iter)\n",
        "\n",
        "        try:\n",
        "            bcls = next(cls_iter)\n",
        "        except StopIteration:\n",
        "            cls_iter = iter(cls_train_loader)\n",
        "            bcls = next(cls_iter)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "            # seg\n",
        "            x = bseg[\"image\"].to(cfg.device, non_blocking=True)\n",
        "            y = bseg[\"mask\"].to(cfg.device, non_blocking=True)\n",
        "            seg_logit, _ = model(x)\n",
        "            loss_seg = bce(seg_logit, y) + dice_loss_with_logits(seg_logit, y)\n",
        "\n",
        "            # cls\n",
        "            x2 = bcls[\"image\"].to(cfg.device, non_blocking=True)\n",
        "            y2 = bcls[\"label\"].to(cfg.device, non_blocking=True)\n",
        "            _, cls_logit = model(x2)\n",
        "            loss_cls = cls_criterion(cls_logit, y2)\n",
        "\n",
        "            loss = cfg.seg_w * loss_seg + cfg.cls_w * loss_cls\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running[\"loss\"] += float(loss.item())\n",
        "        running[\"loss_seg\"] += float(loss_seg.item())\n",
        "        running[\"loss_cls\"] += float(loss_cls.item())\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": running[\"loss\"]/(i+1),\n",
        "            \"seg\": running[\"loss_seg\"]/(i+1),\n",
        "            \"cls\": running[\"loss_cls\"]/(i+1),\n",
        "            \"lr\": scheduler.get_last_lr()[0]\n",
        "        })\n",
        "\n",
        "    # ✅ safe scheduler order: optimizer steps already happened inside loop\n",
        "    scheduler.step()\n",
        "    return {k: v/steps for k, v in running.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_segmentation_mc(epoch: int, export_n: int = 2):\n",
        "    do_full = (epoch % cfg.mc_every == 0)\n",
        "    mc_T = cfg.mc_samples if do_full else cfg.mc_samples_fast\n",
        "\n",
        "    enable_dropout_only(model)\n",
        "\n",
        "    dices, bfs, hd95s_px = [], [], []\n",
        "    entropies, mis = [], []\n",
        "\n",
        "    export_dir = EXPORT_DIR / f\"epoch_{epoch:03d}\"\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for idx, b in enumerate(tqdm(seg_val_loader, desc=f\"[Val-Seg MC(T={mc_T})] Epoch {epoch}\", leave=False)):\n",
        "        if idx >= cfg.val_max_batches_seg:\n",
        "            break\n",
        "\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"mask\"].to(cfg.device)\n",
        "\n",
        "        mc_probs = []\n",
        "        for _ in range(mc_T):\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "                seg_logit, _ = model(x)\n",
        "                prob = torch.sigmoid(seg_logit).squeeze(0).squeeze(0)\n",
        "            if prob.ndim != 2:\n",
        "                continue\n",
        "            mc_probs.append(prob.detach().float().cpu().numpy())\n",
        "\n",
        "        if len(mc_probs) == 0:\n",
        "            continue\n",
        "\n",
        "        mc_probs = np.stack(mc_probs, axis=0)  # [T,H,W]\n",
        "        p_lesion = mc_probs.mean(axis=0).astype(np.float32)\n",
        "\n",
        "        pred_mask = (p_lesion > 0.5).astype(np.uint8)\n",
        "        gt_mask = (y.squeeze().detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        inter = (pred_mask & gt_mask).sum()\n",
        "        union = pred_mask.sum() + gt_mask.sum()\n",
        "        dice = (2 * inter / (union + 1e-6)) if union > 0 else 1.0\n",
        "        dices.append(float(dice))\n",
        "\n",
        "        bfs.append(bf_score(pred_mask, gt_mask, tol_px=2))\n",
        "        hd95s_px.append(hd95(pred_mask, gt_mask))\n",
        "\n",
        "        ent_map = predictive_entropy(p_lesion)\n",
        "        mi_map = mutual_information(mc_probs) if mc_T > 1 else np.zeros_like(ent_map)\n",
        "\n",
        "        entropies.append(float(ent_map.mean()))\n",
        "        mis.append(float(mi_map.mean()))\n",
        "\n",
        "        if do_full and idx < export_n:\n",
        "            p_boundary = compute_boundary_prob_from_plesion(p_lesion)\n",
        "            tw_mm = transition_width_map_mm(p_lesion)\n",
        "\n",
        "            np.save(export_dir / f\"val{idx:03d}_p_lesion.npy\", p_lesion)\n",
        "            np.save(export_dir / f\"val{idx:03d}_p_boundary.npy\", p_boundary)\n",
        "            np.save(export_dir / f\"val{idx:03d}_entropy.npy\", ent_map.astype(np.float32))\n",
        "            np.save(export_dir / f\"val{idx:03d}_mi.npy\", mi_map.astype(np.float32))\n",
        "            np.save(export_dir / f\"val{idx:03d}_transition_width_mm.npy\", tw_mm)\n",
        "\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_p_lesion.png\", p_lesion, \"p_lesion (mean prob)\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_p_boundary.png\", p_boundary, \"p_boundary (|∇p| normalized)\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_entropy.png\", ent_map, \"Predictive entropy\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_mi.png\", mi_map, \"Mutual information\")\n",
        "            save_map_with_mm_axis(export_dir / f\"val{idx:03d}_transition_width_mm.png\", tw_mm, \"Transition width (mm)\")\n",
        "\n",
        "    val_dice = float(np.mean(dices)) if dices else 0.0\n",
        "    val_bf   = float(np.mean(bfs)) if bfs else 0.0\n",
        "    val_hd95_mm = float(np.mean(hd95s_px) * MM_PER_PIXEL) if hd95s_px else 0.0\n",
        "    mean_ent = float(np.mean(entropies)) if entropies else 0.0\n",
        "    mean_mi  = float(np.mean(mis)) if mis else 0.0\n",
        "\n",
        "    return {\n",
        "        \"val_dice\": val_dice,\n",
        "        \"val_bf\": val_bf,\n",
        "        \"val_hd95_mm\": val_hd95_mm,\n",
        "        \"val_pred_entropy_mean\": mean_ent,\n",
        "        \"val_mi_mean\": mean_mi,\n",
        "        \"mc_T\": mc_T,\n",
        "        \"mc_full\": bool(do_full),\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_classification(epoch: int):\n",
        "    model.eval()\n",
        "    all_logits, all_labels = [], []\n",
        "\n",
        "    for bi, b in enumerate(tqdm(cls_val_loader, desc=f\"[Val-Cls] Epoch {epoch}\", leave=False)):\n",
        "        if bi >= cfg.val_max_batches_cls:\n",
        "            break\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"label\"].to(cfg.device)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "            _, logits = model(x)\n",
        "\n",
        "        all_logits.append(logits.detach().float().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "\n",
        "    if not all_logits:\n",
        "        return {\"val_acc\": 0.0, \"val_ece\": 0.0, \"val_aurc\": 0.0, \"val_nll\": 0.0, \"val_brier\": 0.0}\n",
        "\n",
        "    logits = np.concatenate(all_logits, axis=0)\n",
        "    labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    probs = softmax_np(logits)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    acc = float((pred == labels).mean())\n",
        "\n",
        "    ece = ece_score(probs, labels, n_bins=15)\n",
        "    nll = nll_score(probs, labels)\n",
        "    br  = brier_score(probs, labels)\n",
        "\n",
        "    unc = predictive_entropy(probs)\n",
        "    cov, risk = risk_coverage_curve(probs, labels, unc)\n",
        "    A = aurc(cov, risk)\n",
        "\n",
        "    export_dir = EXPORT_DIR / f\"epoch_{epoch:03d}\"\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    np.save(export_dir / \"risk_coverage_coverage.npy\", cov.astype(np.float32))\n",
        "    np.save(export_dir / \"risk_coverage_risk.npy\", risk.astype(np.float32))\n",
        "\n",
        "    plt.figure(figsize=(4, 3), dpi=150)\n",
        "    plt.plot(cov, risk)\n",
        "    plt.xlabel(\"Coverage\")\n",
        "    plt.ylabel(\"Risk (error rate)\")\n",
        "    plt.title(f\"Risk–Coverage (AURC={A:.4f})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(export_dir / \"risk_coverage_curve.png\", bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    return {\"val_acc\": acc, \"val_ece\": float(ece), \"val_aurc\": float(A), \"val_nll\": float(nll), \"val_brier\": float(br)}\n",
        "\n",
        "# =========================================================\n",
        "# Early stopping\n",
        "# =========================================================\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=10, min_delta=1e-4):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best = -1e18\n",
        "        self.bad = 0\n",
        "    def step(self, score: float) -> bool:\n",
        "        if score > self.best + self.min_delta:\n",
        "            self.best = score\n",
        "            self.bad = 0\n",
        "            return False\n",
        "        self.bad += 1\n",
        "        return self.bad >= self.patience\n",
        "\n",
        "def composite_val_score(seg_m: dict, cls_m: dict) -> float:\n",
        "    dice = seg_m[\"val_dice\"]\n",
        "    bf = seg_m[\"val_bf\"]\n",
        "    hd = seg_m[\"val_hd95_mm\"]\n",
        "    acc = cls_m[\"val_acc\"]\n",
        "    ece = cls_m[\"val_ece\"]\n",
        "    aurc_v = cls_m[\"val_aurc\"]\n",
        "    nll = cls_m[\"val_nll\"]\n",
        "    brier = cls_m[\"val_brier\"]\n",
        "\n",
        "    score = (\n",
        "        2.0 * dice +\n",
        "        1.0 * bf +\n",
        "        1.0 * acc -\n",
        "        0.25 * math.log(1.0 + hd) -\n",
        "        0.5 * ece -\n",
        "        0.5 * aurc_v -\n",
        "        0.1 * nll -\n",
        "        0.1 * brier\n",
        "    )\n",
        "    return float(score)\n",
        "\n",
        "stopper = EarlyStopper(patience=cfg.patience, min_delta=cfg.min_delta)\n",
        "\n",
        "# =========================================================\n",
        "# Clear cache\n",
        "# =========================================================\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# =========================================================\n",
        "# Resume\n",
        "# =========================================================\n",
        "start_epoch, best_score, best_epoch = try_resume()\n",
        "\n",
        "# =========================================================\n",
        "# Fine-tune switch:\n",
        "# - When resuming (usually plateau), you can enable finetune config\n",
        "# =========================================================\n",
        "if cfg.finetune:\n",
        "    # ✅ LR down\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = cfg.finetune_lr\n",
        "    # ✅ cls_w down\n",
        "    cfg.cls_w = cfg.finetune_cls_w\n",
        "    print(f\"[Finetune] Enabled: lr={cfg.finetune_lr} cls_w={cfg.cls_w} cls_loss={cfg.cls_loss}\")\n",
        "\n",
        "# =========================================================\n",
        "# Train loop\n",
        "# =========================================================\n",
        "for epoch in range(start_epoch, cfg.epochs + 1):\n",
        "    train_m = train_one_epoch(epoch)\n",
        "    seg_m = validate_segmentation_mc(epoch, export_n=2)\n",
        "    cls_m = validate_classification(epoch)\n",
        "\n",
        "    val_score = composite_val_score(seg_m, cls_m)\n",
        "\n",
        "    metrics = {**train_m, **seg_m, **cls_m,\n",
        "               \"val_score\": val_score,\n",
        "               \"epoch\": epoch,\n",
        "               \"mm_per_pixel\": MM_PER_PIXEL,\n",
        "               \"field_size_mm\": FIELD_SIZE_MM,\n",
        "               \"image_size\": IMAGE_SIZE,\n",
        "               \"amp\": cfg.amp,\n",
        "               \"steps_per_epoch\": cfg.steps_per_epoch,\n",
        "               \"cls_w\": cfg.cls_w,\n",
        "               \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "               \"cls_loss\": cfg.cls_loss}\n",
        "\n",
        "    # log\n",
        "    with open(CHECKPOINT_DIR.parent / \"train_log.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(pd.Series(metrics).to_json() + \"\\n\")\n",
        "\n",
        "    save_checkpoint(CHECKPOINT_DIR / f\"epoch_{epoch:03d}.pt\", model, optimizer, scheduler, epoch, metrics)\n",
        "\n",
        "    if val_score > best_score:\n",
        "        best_score = val_score\n",
        "        best_epoch = epoch\n",
        "        save_checkpoint(CHECKPOINT_DIR / \"best.pt\", model, optimizer, scheduler, epoch, metrics)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch:03d}] \"\n",
        "        f\"loss={train_m['loss']:.4f} | \"\n",
        "        f\"Dice={seg_m['val_dice']:.4f} BF={seg_m['val_bf']:.4f} HD95(mm)={seg_m['val_hd95_mm']:.3f} \"\n",
        "        f\"(MC T={seg_m['mc_T']}, full={seg_m['mc_full']}) | \"\n",
        "        f\"Acc={cls_m['val_acc']:.4f} ECE={cls_m['val_ece']:.4f} AURC={cls_m['val_aurc']:.4f} \"\n",
        "        f\"NLL={cls_m['val_nll']:.4f} Brier={cls_m['val_brier']:.4f} | \"\n",
        "        f\"val_score={val_score:.4f} best={best_score:.4f} (ep{best_epoch}) | \"\n",
        "        f\"lr={optimizer.param_groups[0]['lr']:.1e} cls_w={cfg.cls_w:.2f}\"\n",
        "    )\n",
        "\n",
        "    if stopper.step(val_score):\n",
        "        print(f\"Early stopping at epoch {epoch}. Best epoch={best_epoch}, best_score={best_score:.4f}\")\n",
        "        break\n",
        "\n",
        "print(f\"Training finished. Best epoch: {best_epoch}, best score: {best_score:.4f}\")\n",
        "print(f\"Exports saved to: {EXPORT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "W5v80CJU-Txe",
        "outputId": "a1149f2b-c3be-44d4-8304-b3a750c25a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Resume] Loaded: best.pt | start_epoch=31 | best_score=2.6856 (ep30)\n",
            "[Finetune] Enabled: lr=0.0001 cls_w=0.3 cls_loss=focal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 031] loss=0.2164 | Dice=0.8469 BF=0.4001 HD95(mm)=1.411 (MC T=2, full=False) | Acc=0.7865 ECE=0.0320 AURC=0.0575 NLL=0.4625 Brier=0.2820 | val_score=2.5412 best=2.6856 (ep30) | lr=1.0e-04 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 032] loss=0.2102 | Dice=0.8541 BF=0.4268 HD95(mm)=1.382 (MC T=2, full=False) | Acc=0.7719 ECE=0.0416 AURC=0.0634 NLL=0.4975 Brier=0.3037 | val_score=2.5572 best=2.6856 (ep30) | lr=1.0e-04 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 033] loss=0.2039 | Dice=0.8514 BF=0.4127 HD95(mm)=1.324 (MC T=2, full=False) | Acc=0.7635 ECE=0.0482 AURC=0.0681 NLL=0.5441 Brier=0.3256 | val_score=2.5230 best=2.6856 (ep30) | lr=9.9e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 034] loss=0.2009 | Dice=0.8457 BF=0.4180 HD95(mm)=1.379 (MC T=2, full=False) | Acc=0.7260 ECE=0.0490 AURC=0.0847 NLL=0.5690 Brier=0.3439 | val_score=2.4606 best=2.6856 (ep30) | lr=9.9e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 035] loss=0.1957 | Dice=0.8485 BF=0.3853 HD95(mm)=1.389 (MC T=8, full=True) | Acc=0.7427 ECE=0.0595 AURC=0.0774 NLL=0.5853 Brier=0.3436 | val_score=2.4459 best=2.6856 (ep30) | lr=9.8e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 036] loss=0.1928 | Dice=0.8534 BF=0.4336 HD95(mm)=1.328 (MC T=2, full=False) | Acc=0.7490 ECE=0.0659 AURC=0.0828 NLL=0.5297 Brier=0.3232 | val_score=2.5184 best=2.6856 (ep30) | lr=9.8e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 037] loss=0.1899 | Dice=0.8535 BF=0.4269 HD95(mm)=1.334 (MC T=2, full=False) | Acc=0.7500 ECE=0.0426 AURC=0.0801 NLL=0.5273 Brier=0.3214 | val_score=2.5258 best=2.6856 (ep30) | lr=9.7e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 038] loss=0.1866 | Dice=0.8595 BF=0.4113 HD95(mm)=1.261 (MC T=2, full=False) | Acc=0.7198 ECE=0.0501 AURC=0.0922 NLL=0.6242 Brier=0.3673 | val_score=2.4759 best=2.6856 (ep30) | lr=9.6e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 039] loss=0.1777 | Dice=0.8526 BF=0.4222 HD95(mm)=1.390 (MC T=2, full=False) | Acc=0.7448 ECE=0.0537 AURC=0.0777 NLL=0.5420 Brier=0.3291 | val_score=2.5015 best=2.6856 (ep30) | lr=9.5e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 040] loss=0.1811 | Dice=0.8584 BF=0.4269 HD95(mm)=1.260 (MC T=8, full=True) | Acc=0.7229 ECE=0.0445 AURC=0.0874 NLL=0.5670 Brier=0.3456 | val_score=2.5056 best=2.6856 (ep30) | lr=9.3e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 041] loss=0.1778 | Dice=0.8513 BF=0.3975 HD95(mm)=1.301 (MC T=2, full=False) | Acc=0.7500 ECE=0.0347 AURC=0.0748 NLL=0.5853 Brier=0.3442 | val_score=2.4942 best=2.6856 (ep30) | lr=9.2e-05 cls_w=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2433547193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;31m# =========================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0mtrain_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m     \u001b[0mseg_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_segmentation_mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0mcls_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2433547193.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mbseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0mseg_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#递归遍历整个目录（含子文件夹），把所有 .npy 转成同名 .csv，并放回原目录，适用于 Google Colab + Drive\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ROOT_DIR = \"/content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net\"\n",
        "\n",
        "def npy_to_csv(npy_path):\n",
        "    data = np.load(npy_path)\n",
        "\n",
        "    # 处理不同维度\n",
        "    if data.ndim == 1:\n",
        "        df = pd.DataFrame(data, columns=[\"value\"])\n",
        "    elif data.ndim == 2:\n",
        "        df = pd.DataFrame(data)\n",
        "    else:\n",
        "        # 高维数据：flatten 成 (N, C)\n",
        "        data_flat = data.reshape(data.shape[0], -1)\n",
        "        df = pd.DataFrame(data_flat)\n",
        "\n",
        "    csv_path = npy_path.replace(\".npy\", \".csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"✔ Converted: {npy_path} → {csv_path}\")\n",
        "\n",
        "# 递归遍历\n",
        "for root, _, files in os.walk(ROOT_DIR):\n",
        "    for file in files:\n",
        "        if file.endswith(\".npy\"):\n",
        "            npy_to_csv(os.path.join(root, file))\n",
        "\n",
        "print(\"✅ All .npy files have been converted to .csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV-3uRcO3VkD",
        "outputId": "3f4d09e0-5174-41cd-940a-15cc86458cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_001/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_001/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_001/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_001/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_002/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_002/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_002/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_002/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_003/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_003/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_003/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_003/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_004/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_004/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_004/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_004/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_005/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_006/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_006/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_006/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_006/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_007/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_007/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_007/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_007/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_008/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_008/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_008/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_008/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_009/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_009/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_009/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_009/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_010/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_011/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_011/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_011/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_011/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_012/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_012/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_012/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_012/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_013/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_013/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_013/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_013/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_014/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_014/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_014/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_014/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_015/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_016/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_016/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_016/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_016/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_017/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_017/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_017/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_017/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_018/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_018/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_018/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_018/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_019/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_019/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_019/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_019/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_020/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_021/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_021/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_021/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_021/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_022/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_022/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_022/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_022/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_023/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_023/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_023/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_023/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_024/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_024/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_024/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_024/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_025/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_026/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_026/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_026/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_026/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_027/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_027/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_027/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_027/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_028/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_028/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_028/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_028/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_029/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_029/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_029/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_029/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_030/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_031/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_031/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_031/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_031/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_032/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_032/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_032/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_032/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_033/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_033/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_033/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_033/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_034/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_034/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_034/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_034/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_035/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_036/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_036/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_036/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_036/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_037/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_037/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_037/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_037/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_038/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_038/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_038/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_038/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_039/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_039/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_039/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_039/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val000_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_p_lesion.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_p_lesion.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_p_boundary.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_p_boundary.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_entropy.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_entropy.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_mi.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_mi.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_transition_width_mm.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/val001_transition_width_mm.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_040/risk_coverage_risk.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_041/risk_coverage_coverage.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_041/risk_coverage_coverage.csv\n",
            "✔ Converted: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_041/risk_coverage_risk.npy → /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports/epoch_041/risk_coverage_risk.csv\n",
            "✅ All .npy files have been converted to .csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "ROOT_DIR = \"/content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net\"\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for root, _, files in os.walk(ROOT_DIR):\n",
        "    for file in files:\n",
        "        if file.endswith(\".jsonl\"):\n",
        "            jsonl_path = os.path.join(root, file)\n",
        "            try:\n",
        "                df = pd.read_json(jsonl_path, lines=True)\n",
        "                df[\"source_file\"] = jsonl_path  # 标记来源\n",
        "                dfs.append(df)\n",
        "                print(f\"✔ Loaded: {jsonl_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"✘ Failed to load {jsonl_path}: {e}\")\n",
        "\n",
        "# 合并所有日志\n",
        "if len(dfs) > 0:\n",
        "    all_logs_df = pd.concat(dfs, ignore_index=True)\n",
        "    print(\"✅ DataFrame created successfully\")\n",
        "    display(all_logs_df.head())\n",
        "else:\n",
        "    print(\"⚠️ No .jsonl files found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "qvQ2-4rx4zve",
        "outputId": "fb51d86f-2d5d-4ba1-dca7-2859557645e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Loaded: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/train_log.jsonl\n",
            "✅ DataFrame created successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       loss  loss_seg  loss_cls  val_dice    val_bf  val_hd95_mm  \\\n",
              "0  1.191900  0.907730  0.568339  0.755712  0.258117     2.076796   \n",
              "1  0.925326  0.653624  0.543404  0.770972  0.270507     1.933957   \n",
              "2  0.780355  0.526947  0.506816  0.784604  0.309778     2.037588   \n",
              "3  0.725394  0.476267  0.498256  0.756719  0.256083     2.018875   \n",
              "4  0.694706  0.446966  0.495480  0.801430  0.353455     1.877534   \n",
              "\n",
              "   val_pred_entropy_mean  val_mi_mean  mc_T  mc_full  ...  epoch  \\\n",
              "0              53.147146     0.174274     2    False  ...      1   \n",
              "1              35.667731     0.198982     2    False  ...      2   \n",
              "2              28.413414     0.132802     2    False  ...      3   \n",
              "3              16.868947     0.100238     2    False  ...      4   \n",
              "4              15.144863     0.115540     2    False  ...      4   \n",
              "\n",
              "   mm_per_pixel  field_size_mm  image_size   amp  steps_per_epoch  cls_w  lr  \\\n",
              "0      0.058594             15         256  True              350    NaN NaN   \n",
              "1      0.058594             15         256  True              350    NaN NaN   \n",
              "2      0.058594             15         256  True              350    NaN NaN   \n",
              "3      0.058594             15         256  True              350    NaN NaN   \n",
              "4      0.058594             15         256  True              350    NaN NaN   \n",
              "\n",
              "   cls_loss                                        source_file  \n",
              "0       NaN  /content/drive/My Drive/seg_class_skin_cancer/...  \n",
              "1       NaN  /content/drive/My Drive/seg_class_skin_cancer/...  \n",
              "2       NaN  /content/drive/My Drive/seg_class_skin_cancer/...  \n",
              "3       NaN  /content/drive/My Drive/seg_class_skin_cancer/...  \n",
              "4       NaN  /content/drive/My Drive/seg_class_skin_cancer/...  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc19c91a-7110-48d4-93ad-77b9f20b0fa7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>loss_seg</th>\n",
              "      <th>loss_cls</th>\n",
              "      <th>val_dice</th>\n",
              "      <th>val_bf</th>\n",
              "      <th>val_hd95_mm</th>\n",
              "      <th>val_pred_entropy_mean</th>\n",
              "      <th>val_mi_mean</th>\n",
              "      <th>mc_T</th>\n",
              "      <th>mc_full</th>\n",
              "      <th>...</th>\n",
              "      <th>epoch</th>\n",
              "      <th>mm_per_pixel</th>\n",
              "      <th>field_size_mm</th>\n",
              "      <th>image_size</th>\n",
              "      <th>amp</th>\n",
              "      <th>steps_per_epoch</th>\n",
              "      <th>cls_w</th>\n",
              "      <th>lr</th>\n",
              "      <th>cls_loss</th>\n",
              "      <th>source_file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.191900</td>\n",
              "      <td>0.907730</td>\n",
              "      <td>0.568339</td>\n",
              "      <td>0.755712</td>\n",
              "      <td>0.258117</td>\n",
              "      <td>2.076796</td>\n",
              "      <td>53.147146</td>\n",
              "      <td>0.174274</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058594</td>\n",
              "      <td>15</td>\n",
              "      <td>256</td>\n",
              "      <td>True</td>\n",
              "      <td>350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/My Drive/seg_class_skin_cancer/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.925326</td>\n",
              "      <td>0.653624</td>\n",
              "      <td>0.543404</td>\n",
              "      <td>0.770972</td>\n",
              "      <td>0.270507</td>\n",
              "      <td>1.933957</td>\n",
              "      <td>35.667731</td>\n",
              "      <td>0.198982</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.058594</td>\n",
              "      <td>15</td>\n",
              "      <td>256</td>\n",
              "      <td>True</td>\n",
              "      <td>350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/My Drive/seg_class_skin_cancer/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.780355</td>\n",
              "      <td>0.526947</td>\n",
              "      <td>0.506816</td>\n",
              "      <td>0.784604</td>\n",
              "      <td>0.309778</td>\n",
              "      <td>2.037588</td>\n",
              "      <td>28.413414</td>\n",
              "      <td>0.132802</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.058594</td>\n",
              "      <td>15</td>\n",
              "      <td>256</td>\n",
              "      <td>True</td>\n",
              "      <td>350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/My Drive/seg_class_skin_cancer/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.725394</td>\n",
              "      <td>0.476267</td>\n",
              "      <td>0.498256</td>\n",
              "      <td>0.756719</td>\n",
              "      <td>0.256083</td>\n",
              "      <td>2.018875</td>\n",
              "      <td>16.868947</td>\n",
              "      <td>0.100238</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.058594</td>\n",
              "      <td>15</td>\n",
              "      <td>256</td>\n",
              "      <td>True</td>\n",
              "      <td>350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/My Drive/seg_class_skin_cancer/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.694706</td>\n",
              "      <td>0.446966</td>\n",
              "      <td>0.495480</td>\n",
              "      <td>0.801430</td>\n",
              "      <td>0.353455</td>\n",
              "      <td>1.877534</td>\n",
              "      <td>15.144863</td>\n",
              "      <td>0.115540</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.058594</td>\n",
              "      <td>15</td>\n",
              "      <td>256</td>\n",
              "      <td>True</td>\n",
              "      <td>350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/drive/My Drive/seg_class_skin_cancer/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc19c91a-7110-48d4-93ad-77b9f20b0fa7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc19c91a-7110-48d4-93ad-77b9f20b0fa7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc19c91a-7110-48d4-93ad-77b9f20b0fa7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (26) exceeds max_columns (20) limiting to first (20) columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# VALIDATION-ONLY Inference + Export (NO TRAINING)\n",
        "# Hybrid CNN–ViT–U-Net (Seg + Cls)\n",
        "# Uses OFFICIAL ISIC 2018 VALIDATION folders (Task1 + Task3)\n",
        "# Physical size: 15mm × 15mm → 256 × 256 px\n",
        "#\n",
        "# Exports:\n",
        "#  Seg: p_lesion, p_boundary, entropy, MI, transition_width_mm (npy + png with mm axis)\n",
        "#  Cls: logits/probs/labels/uncertainty(entropy) + risk-coverage curve (AURC)\n",
        "#\n",
        "# Speed:\n",
        "#  - workers=2\n",
        "#  - AMP autocast\n",
        "# =========================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import math, random, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Performance settings\n",
        "# -----------------------------\n",
        "cv2.setNumThreads(0)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Your VALIDATION paths (✅ use these)\n",
        "# -----------------------------\n",
        "SEG_IMAGE_DIR = Path(\"/content/drive/My Drive/isic2018/Validation\")\n",
        "SEG_MASK_DIR  = Path(\"/content/drive/My Drive/isic2018/ValidationTruth\")\n",
        "\n",
        "CLS_IMAGE_DIR = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Validation_Input\".strip())\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\".strip())\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"/content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/checkpoints\".strip())\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EXPORT_DIR = CHECKPOINT_DIR.parent / \"exports_validation\"\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Physical size\n",
        "# -----------------------------\n",
        "FIELD_SIZE_MM = 15.0\n",
        "IMAGE_SIZE = 256\n",
        "MM_PER_PIXEL = FIELD_SIZE_MM / IMAGE_SIZE\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utils\n",
        "# -----------------------------\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "def pick_checkpoint(ckpt_dir: Path) -> Path:\n",
        "    best_path = ckpt_dir / \"best.pt\"\n",
        "    if best_path.exists():\n",
        "        return best_path\n",
        "\n",
        "    pts = sorted(ckpt_dir.glob(\"epoch_*.pt\"))\n",
        "    if not pts:\n",
        "        raise FileNotFoundError(f\"No checkpoint found in: {ckpt_dir}\")\n",
        "\n",
        "    def key(p: Path):\n",
        "        m = re.search(r\"epoch_(\\d+)\\.pt$\", p.name)\n",
        "        return int(m.group(1)) if m else -1\n",
        "\n",
        "    pts = sorted(pts, key=key)\n",
        "    return pts[-1]\n",
        "\n",
        "def save_map_with_mm_axis(path_png: Path, arr: np.ndarray, title: str):\n",
        "    arr = np.asarray(arr)\n",
        "    if arr.ndim != 2:\n",
        "        print(f\"[WARN] Skip saving {title}: invalid shape={arr.shape}\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(5, 4), dpi=150)\n",
        "    plt.imshow(arr, extent=(0, FIELD_SIZE_MM, FIELD_SIZE_MM, 0))\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    plt.xlabel(\"x (mm)\")\n",
        "    plt.ylabel(\"y (mm)\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path_png, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset helpers\n",
        "# -----------------------------\n",
        "def list_images_any_ext(folder: Path):\n",
        "    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]\n",
        "    paths = []\n",
        "    for e in exts:\n",
        "        paths.extend(folder.glob(e))\n",
        "    return sorted(paths)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Segmentation (Task 1 VALIDATION)\n",
        "# =========================================================\n",
        "class ISICSegValDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Uses official validation folders.\n",
        "    Mask naming varies by pack, so we implement:\n",
        "      - exact stem match: <stem>_segmentation.png (common in training)\n",
        "      - or <stem>.png in ValidationTruth (common in official val)\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir: Path, mask_dir: Path, image_size: int = 256):\n",
        "        self.image_paths = list_images_any_ext(image_dir)\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.pairs = []\n",
        "        for p in self.image_paths:\n",
        "            stem = p.stem\n",
        "\n",
        "            cand1 = mask_dir / f\"{stem}_segmentation.png\"\n",
        "            cand2 = mask_dir / f\"{stem}.png\"\n",
        "            cand3 = mask_dir / f\"{stem}_segmentation.PNG\"\n",
        "            cand4 = mask_dir / f\"{stem}.PNG\"\n",
        "\n",
        "            if cand1.exists():\n",
        "                mp = cand1\n",
        "            elif cand2.exists():\n",
        "                mp = cand2\n",
        "            elif cand3.exists():\n",
        "                mp = cand3\n",
        "            elif cand4.exists():\n",
        "                mp = cand4\n",
        "            else:\n",
        "                # skip if no mask\n",
        "                continue\n",
        "            self.pairs.append((p, mp))\n",
        "\n",
        "        if len(self.pairs) == 0:\n",
        "            raise ValueError(f\"No (image,mask) pairs found. Check mask naming in: {mask_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path = self.pairs[idx]\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Cannot read mask: {mask_path}\")\n",
        "\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "        img_t = torch.from_numpy(img).permute(2, 0, 1)     # [3,H,W]\n",
        "        mask_t = torch.from_numpy(mask).unsqueeze(0)       # [1,H,W]\n",
        "        return {\"image\": img_t, \"mask\": mask_t, \"id\": img_path.stem}\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Classification (Task 3 VALIDATION one-hot CSV)\n",
        "# =========================================================\n",
        "class ISICClsValDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Expects one-hot CSV:\n",
        "      columns: image, MEL, NV, BCC, AKIEC, BKL, DF, VASC\n",
        "    Converts to 3-class:\n",
        "      malignant: MEL/BCC -> 2\n",
        "      intermediate: AKIEC -> 1\n",
        "      benign: NV/BKL/DF/VASC -> 0\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir: Path, label_csv: Path, image_size: int = 256):\n",
        "        self.image_dir = image_dir\n",
        "        self.df = pd.read_csv(label_csv)\n",
        "        self.df.columns = self.df.columns.str.strip()\n",
        "        self.image_size = image_size\n",
        "\n",
        "        onehot_classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "        if (\"image\" not in self.df.columns) or (not all(c in self.df.columns for c in onehot_classes)):\n",
        "            raise ValueError(f\"CSV missing expected columns. Got: {list(self.df.columns)}\")\n",
        "\n",
        "        self.records = []\n",
        "        for _, row in self.df.iterrows():\n",
        "            img_id = str(row[\"image\"]).strip()\n",
        "\n",
        "            malignant = (row[\"MEL\"] == 1) or (row[\"BCC\"] == 1)\n",
        "            intermediate = (row[\"AKIEC\"] == 1)\n",
        "            benign = (row[\"NV\"] == 1) or (row[\"BKL\"] == 1) or (row[\"DF\"] == 1) or (row[\"VASC\"] == 1)\n",
        "\n",
        "            if malignant:\n",
        "                label = 2\n",
        "            elif intermediate:\n",
        "                label = 1\n",
        "            elif benign:\n",
        "                label = 0\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            self.records.append((img_id, label))\n",
        "\n",
        "        if len(self.records) == 0:\n",
        "            raise ValueError(\"No valid records in validation CSV.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id, label = self.records[idx]\n",
        "\n",
        "        # support jpg/png\n",
        "        jpg = self.image_dir / f\"{img_id}.jpg\"\n",
        "        png = self.image_dir / f\"{img_id}.png\"\n",
        "        jpeg = self.image_dir / f\"{img_id}.jpeg\"\n",
        "\n",
        "        img_path = jpg if jpg.exists() else (png if png.exists() else (jpeg if jpeg.exists() else None))\n",
        "        if img_path is None:\n",
        "            raise FileNotFoundError(f\"Cannot find image for id={img_id} in {self.image_dir}\")\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img_t = torch.from_numpy(img).permute(2, 0, 1)\n",
        "\n",
        "        return {\"image\": img_t, \"label\": torch.tensor(label, dtype=torch.long), \"id\": img_id}\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Model blocks (same as training)\n",
        "# =========================================================\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GELU()\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(ConvBNAct(in_ch, out_ch), ConvBNAct(out_ch, out_ch))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=32):\n",
        "        super().__init__()\n",
        "        self.e1 = ConvBlock(in_ch, base_ch)\n",
        "        self.e2 = ConvBlock(base_ch, base_ch * 2)\n",
        "        self.e3 = ConvBlock(base_ch * 2, base_ch * 4)\n",
        "        self.e4 = ConvBlock(base_ch * 4, base_ch * 8)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "    def forward(self, x):\n",
        "        f1 = self.e1(x)\n",
        "        f2 = self.e2(self.pool(f1))\n",
        "        f3 = self.e3(self.pool(f2))\n",
        "        f4 = self.e4(self.pool(f3))\n",
        "        return [f1, f2, f3, f4]\n",
        "\n",
        "class ViTBottleneck(nn.Module):\n",
        "    def __init__(self, dim, depth=2, heads=4, drop=0.1):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=dim, nhead=heads, dim_feedforward=dim*4,\n",
        "            dropout=drop, activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, depth)\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        tokens = self.encoder(tokens)\n",
        "        return tokens.transpose(1, 2).reshape(b, c, h, w)\n",
        "\n",
        "class UNetDecoder(nn.Module):\n",
        "    def __init__(self, base_ch=32, out_ch=1, dropout_p=0.10):\n",
        "        super().__init__()\n",
        "        self.up3 = nn.ConvTranspose2d(base_ch*8, base_ch*4, 2, 2)\n",
        "        self.d3  = ConvBlock(base_ch*8, base_ch*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base_ch*4, base_ch*2, 2, 2)\n",
        "        self.d2  = ConvBlock(base_ch*4, base_ch*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_ch*2, base_ch, 2, 2)\n",
        "        self.d1  = ConvBlock(base_ch*2, base_ch)\n",
        "        self.drop = nn.Dropout2d(dropout_p) if dropout_p > 0 else nn.Identity()\n",
        "        self.out  = nn.Conv2d(base_ch, out_ch, 1)\n",
        "    def forward(self, feats):\n",
        "        f1, f2, f3, f4 = feats\n",
        "        x = self.up3(f4)\n",
        "        x = self.d3(torch.cat([x, f3], dim=1))\n",
        "        x = self.up2(x)\n",
        "        x = self.d2(torch.cat([x, f2], dim=1))\n",
        "        x = self.up1(x)\n",
        "        x = self.d1(torch.cat([x, f1], dim=1))\n",
        "        x = self.drop(x)\n",
        "        return self.out(x)\n",
        "\n",
        "class HybridMTLModel(nn.Module):\n",
        "    def __init__(self, base_ch=32, num_classes=3, seg_dropout=0.10):\n",
        "        super().__init__()\n",
        "        self.encoder = ConvEncoder(3, base_ch)\n",
        "        self.bottleneck = ViTBottleneck(base_ch*8, depth=2, heads=4, drop=0.1)\n",
        "        self.decoder = UNetDecoder(base_ch, out_ch=1, dropout_p=seg_dropout)\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base_ch*8, base_ch*8),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(base_ch*8, num_classes),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x)\n",
        "        feats[-1] = self.bottleneck(feats[-1])\n",
        "        seg_logit = self.decoder(feats)\n",
        "        cls_logit = self.cls_head(feats[-1])\n",
        "        return seg_logit, cls_logit\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Export helpers\n",
        "# =========================================================\n",
        "def predictive_entropy(p: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    if p.ndim >= 2 and p.shape[-1] > 1:\n",
        "        return -(p * np.log(p + eps)).sum(axis=-1)\n",
        "    return -(p*np.log(p+eps) + (1-p)*np.log(1-p+eps))\n",
        "\n",
        "def mutual_information(mc_probs: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    mean_p = mc_probs.mean(axis=0)\n",
        "    H_mean = predictive_entropy(mean_p, eps=eps)\n",
        "    H_each = predictive_entropy(mc_probs, eps=eps)\n",
        "    return H_mean - H_each.mean(axis=0)\n",
        "\n",
        "def compute_boundary_prob_from_plesion(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy)\n",
        "    g = g / (g.max() + 1e-12)\n",
        "    return g.astype(np.float32)\n",
        "\n",
        "def transition_width_map_mm(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy) + 1e-12\n",
        "    width_px = 0.6 / g\n",
        "    width_mm = width_px * MM_PER_PIXEL\n",
        "    return np.clip(width_mm, 0.0, 10.0).astype(np.float32)\n",
        "\n",
        "def softmax_np(logits: np.ndarray) -> np.ndarray:\n",
        "    x = logits - logits.max(axis=1, keepdims=True)\n",
        "    e = np.exp(x)\n",
        "    return e / (e.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def risk_coverage_curve(probs: np.ndarray, labels: np.ndarray, uncertainty: np.ndarray):\n",
        "    n = len(labels)\n",
        "    order = np.argsort(uncertainty)\n",
        "    probs_s = probs[order]\n",
        "    labels_s = labels[order]\n",
        "    pred = probs_s.argmax(axis=1)\n",
        "    err = (pred != labels_s).astype(np.float32)\n",
        "    coverages = np.linspace(1/n, 1.0, n)\n",
        "    risks = np.cumsum(err) / (np.arange(n) + 1)\n",
        "    return coverages, risks\n",
        "\n",
        "def aurc(coverages: np.ndarray, risks: np.ndarray) -> float:\n",
        "    return float(np.trapezoid(risks, coverages))\n",
        "\n",
        "def enable_dropout_only(model: nn.Module):\n",
        "    model.eval()\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
        "            m.train()\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Config\n",
        "# =========================================================\n",
        "@dataclass\n",
        "class InferCfg:\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    amp: bool = True\n",
        "    workers: int = 2\n",
        "\n",
        "    seg_mc_T: int = 8\n",
        "    seg_batch: int = 1\n",
        "    cls_batch: int = 8\n",
        "\n",
        "cfg = InferCfg()\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Build loaders (NO split; use full validation folders)\n",
        "# =========================================================\n",
        "seg_val_ds = ISICSegValDataset(SEG_IMAGE_DIR, SEG_MASK_DIR, image_size=IMAGE_SIZE)\n",
        "cls_val_ds = ISICClsValDataset(CLS_IMAGE_DIR, CLS_LABEL_CSV, image_size=IMAGE_SIZE)\n",
        "\n",
        "print(f\"[VAL-SEG] pairs found = {len(seg_val_ds)}\")\n",
        "print(f\"[VAL-CLS] samples found = {len(cls_val_ds)}\")\n",
        "\n",
        "common_loader_kwargs = dict(\n",
        "    num_workers=cfg.workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True if cfg.workers > 0 else False,\n",
        "    prefetch_factor=2 if cfg.workers > 0 else None\n",
        ")\n",
        "\n",
        "seg_val_loader = DataLoader(seg_val_ds, batch_size=cfg.seg_batch, shuffle=False, **common_loader_kwargs)\n",
        "cls_val_loader = DataLoader(cls_val_ds, batch_size=cfg.cls_batch, shuffle=False, **common_loader_kwargs)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Load model\n",
        "# =========================================================\n",
        "model = HybridMTLModel(base_ch=32, num_classes=3, seg_dropout=0.10).to(cfg.device)\n",
        "ckpt_path = pick_checkpoint(CHECKPOINT_DIR)\n",
        "ckpt = torch.load(ckpt_path, map_location=cfg.device)\n",
        "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "ep = int(ckpt.get(\"epoch\", 0))\n",
        "print(f\"[Load] {ckpt_path.name} | epoch={ep}\")\n",
        "\n",
        "OUT_DIR = EXPORT_DIR / f\"epoch_{ep:03d}\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Export SEG (full validation)\n",
        "# =========================================================\n",
        "@torch.no_grad()\n",
        "def export_seg_full_validation(mc_T: int):\n",
        "    enable_dropout_only(model)\n",
        "    out_dir = OUT_DIR / f\"seg_val_MC{mc_T}\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for i, b in enumerate(tqdm(seg_val_loader, desc=f\"[Export-Seg VAL FULL MC(T={mc_T})]\", leave=True)):\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        sid = b[\"id\"][0] if isinstance(b[\"id\"], (list, tuple)) else str(b[\"id\"])\n",
        "\n",
        "        mc_probs = []\n",
        "        for _ in range(mc_T):\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "                seg_logit, _ = model(x)\n",
        "                prob = torch.sigmoid(seg_logit).squeeze(0).squeeze(0)  # [H,W]\n",
        "            if prob.ndim == 2:\n",
        "                mc_probs.append(prob.detach().float().cpu().numpy())\n",
        "\n",
        "        if len(mc_probs) == 0:\n",
        "            continue\n",
        "\n",
        "        mc_probs = np.stack(mc_probs, axis=0)\n",
        "        p_lesion = mc_probs.mean(axis=0).astype(np.float32)\n",
        "        p_boundary = compute_boundary_prob_from_plesion(p_lesion)\n",
        "        ent_map = predictive_entropy(p_lesion).astype(np.float32)\n",
        "        mi_map  = mutual_information(mc_probs).astype(np.float32) if mc_T > 1 else np.zeros_like(ent_map)\n",
        "        tw_mm   = transition_width_map_mm(p_lesion)\n",
        "\n",
        "        np.save(out_dir / f\"{sid}_p_lesion.npy\", p_lesion)\n",
        "        np.save(out_dir / f\"{sid}_p_boundary.npy\", p_boundary)\n",
        "        np.save(out_dir / f\"{sid}_entropy.npy\", ent_map)\n",
        "        np.save(out_dir / f\"{sid}_mi.npy\", mi_map)\n",
        "        np.save(out_dir / f\"{sid}_transition_width_mm.npy\", tw_mm)\n",
        "\n",
        "        save_map_with_mm_axis(out_dir / f\"{sid}_p_lesion.png\", p_lesion, \"p_lesion\")\n",
        "        save_map_with_mm_axis(out_dir / f\"{sid}_p_boundary.png\", p_boundary, \"p_boundary\")\n",
        "        save_map_with_mm_axis(out_dir / f\"{sid}_entropy.png\", ent_map, \"Predictive entropy\")\n",
        "        save_map_with_mm_axis(out_dir / f\"{sid}_mi.png\", mi_map, \"Mutual information\")\n",
        "        save_map_with_mm_axis(out_dir / f\"{sid}_transition_width_mm.png\", tw_mm, \"Transition width (mm)\")\n",
        "\n",
        "    print(f\"[Seg Export] done -> {out_dir}\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Export CLS (full validation)\n",
        "# =========================================================\n",
        "@torch.no_grad()\n",
        "def export_cls_full_validation():\n",
        "    model.eval()\n",
        "    out_dir = OUT_DIR / \"cls_val\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    all_logits, all_labels = [], []\n",
        "    for b in tqdm(cls_val_loader, desc=\"[Export-Cls VAL FULL]\", leave=True):\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"label\"].to(cfg.device)\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "            _, logits = model(x)\n",
        "        all_logits.append(logits.detach().float().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "\n",
        "    logits = np.concatenate(all_logits, axis=0) if all_logits else np.zeros((0,3), np.float32)\n",
        "    labels = np.concatenate(all_labels, axis=0) if all_labels else np.zeros((0,), np.int64)\n",
        "\n",
        "    probs = softmax_np(logits) if len(labels) else np.zeros_like(logits)\n",
        "    unc  = predictive_entropy(probs).astype(np.float32) if len(labels) else np.zeros((0,), np.float32)\n",
        "\n",
        "    np.save(out_dir / \"logits.npy\", logits.astype(np.float32))\n",
        "    np.save(out_dir / \"probs.npy\", probs.astype(np.float32))\n",
        "    np.save(out_dir / \"labels.npy\", labels.astype(np.int64))\n",
        "    np.save(out_dir / \"uncertainty_entropy.npy\", unc.astype(np.float32))\n",
        "\n",
        "    if len(labels) > 0:\n",
        "        cov, risk = risk_coverage_curve(probs, labels, unc)\n",
        "        A = aurc(cov, risk)\n",
        "        np.save(out_dir / \"risk_coverage_coverage.npy\", cov.astype(np.float32))\n",
        "        np.save(out_dir / \"risk_coverage_risk.npy\", risk.astype(np.float32))\n",
        "\n",
        "        plt.figure(figsize=(4, 3), dpi=150)\n",
        "        plt.plot(cov, risk)\n",
        "        plt.xlabel(\"Coverage\")\n",
        "        plt.ylabel(\"Risk (error rate)\")\n",
        "        plt.title(f\"VAL Risk–Coverage (AURC={A:.4f})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(out_dir / \"risk_coverage_curve.png\", bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "        pred = probs.argmax(axis=1)\n",
        "        acc = float((pred == labels).mean())\n",
        "        print(f\"[VAL-Cls] n={len(labels)} acc={acc:.4f} AURC={A:.4f}\")\n",
        "\n",
        "    print(f\"[Cls Export] done -> {out_dir}\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Run full validation exports\n",
        "# =========================================================\n",
        "export_seg_full_validation(mc_T=cfg.seg_mc_T)\n",
        "export_cls_full_validation()\n",
        "\n",
        "print(f\"✅ Exports saved to: {OUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy0_VItMOE5v",
        "outputId": "1e8e7b8d-5795-49b7-a39e-97ea74a87302"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL-SEG] pairs found = 100\n",
            "[VAL-CLS] samples found = 193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Load] best.pt | epoch=30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   1%|          | 1/100 [00:01<02:20,  1.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   2%|▏         | 2/100 [00:02<02:03,  1.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   3%|▎         | 3/100 [00:03<01:53,  1.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   4%|▍         | 4/100 [00:04<01:45,  1.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   5%|▌         | 5/100 [00:06<02:06,  1.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   6%|▌         | 6/100 [00:09<02:48,  1.79s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   7%|▋         | 7/100 [00:10<02:31,  1.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   8%|▊         | 8/100 [00:11<02:27,  1.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:   9%|▉         | 9/100 [00:13<02:15,  1.49s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  10%|█         | 10/100 [00:14<02:07,  1.42s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  11%|█         | 11/100 [00:15<02:10,  1.47s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  12%|█▏        | 12/100 [00:17<02:03,  1.41s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  13%|█▎        | 13/100 [00:18<01:59,  1.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  14%|█▍        | 14/100 [00:20<02:01,  1.41s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  15%|█▌        | 15/100 [00:21<02:11,  1.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  16%|█▌        | 16/100 [00:23<02:06,  1.51s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  17%|█▋        | 17/100 [00:24<01:51,  1.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  18%|█▊        | 18/100 [00:25<01:39,  1.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  19%|█▉        | 19/100 [00:26<01:39,  1.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  20%|██        | 20/100 [00:27<01:32,  1.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  21%|██        | 21/100 [00:28<01:28,  1.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  22%|██▏       | 22/100 [00:29<01:23,  1.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  23%|██▎       | 23/100 [00:30<01:21,  1.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  24%|██▍       | 24/100 [00:31<01:18,  1.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  25%|██▌       | 25/100 [00:32<01:16,  1.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  26%|██▌       | 26/100 [00:33<01:18,  1.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  27%|██▋       | 27/100 [00:35<01:27,  1.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  28%|██▊       | 28/100 [00:36<01:36,  1.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  29%|██▉       | 29/100 [00:37<01:27,  1.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  30%|███       | 30/100 [00:38<01:21,  1.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  31%|███       | 31/100 [00:39<01:17,  1.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  32%|███▏      | 32/100 [00:40<01:15,  1.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  33%|███▎      | 33/100 [00:41<01:11,  1.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  34%|███▍      | 34/100 [00:42<01:11,  1.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  35%|███▌      | 35/100 [00:43<01:08,  1.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  36%|███▌      | 36/100 [00:44<01:05,  1.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  37%|███▋      | 37/100 [00:45<01:04,  1.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  38%|███▊      | 38/100 [00:47<01:05,  1.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  39%|███▉      | 39/100 [00:48<01:11,  1.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  40%|████      | 40/100 [00:50<01:21,  1.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  41%|████      | 41/100 [00:51<01:14,  1.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  42%|████▏     | 42/100 [00:52<01:07,  1.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  43%|████▎     | 43/100 [00:53<01:05,  1.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  44%|████▍     | 44/100 [00:54<01:01,  1.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  45%|████▌     | 45/100 [00:55<00:59,  1.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  46%|████▌     | 46/100 [00:56<00:57,  1.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  47%|████▋     | 47/100 [00:57<00:57,  1.08s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  48%|████▊     | 48/100 [00:58<00:55,  1.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  49%|████▉     | 49/100 [00:59<00:53,  1.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  50%|█████     | 50/100 [01:01<00:59,  1.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  51%|█████     | 51/100 [01:02<01:03,  1.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  52%|█████▏    | 52/100 [01:03<01:01,  1.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  53%|█████▎    | 53/100 [01:04<00:57,  1.22s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  54%|█████▍    | 54/100 [01:06<00:59,  1.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  55%|█████▌    | 55/100 [01:07<00:53,  1.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  56%|█████▌    | 56/100 [01:08<00:51,  1.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  57%|█████▋    | 57/100 [01:09<00:49,  1.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  58%|█████▊    | 58/100 [01:10<00:48,  1.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  59%|█████▉    | 59/100 [01:11<00:47,  1.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  60%|██████    | 60/100 [01:12<00:44,  1.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  61%|██████    | 61/100 [01:14<00:47,  1.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  62%|██████▏   | 62/100 [01:15<00:49,  1.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  63%|██████▎   | 63/100 [01:17<00:49,  1.34s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  64%|██████▍   | 64/100 [01:18<00:44,  1.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  65%|██████▌   | 65/100 [01:19<00:41,  1.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  66%|██████▌   | 66/100 [01:20<00:38,  1.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  67%|██████▋   | 67/100 [01:21<00:35,  1.09s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  68%|██████▊   | 68/100 [01:22<00:35,  1.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  69%|██████▉   | 69/100 [01:23<00:36,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  70%|███████   | 70/100 [01:24<00:34,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  71%|███████   | 71/100 [01:25<00:32,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  72%|███████▏  | 72/100 [01:27<00:38,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  73%|███████▎  | 73/100 [01:29<00:39,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  74%|███████▍  | 74/100 [01:30<00:35,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  75%|███████▌  | 75/100 [01:31<00:31,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  76%|███████▌  | 76/100 [01:32<00:29,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  77%|███████▋  | 77/100 [01:33<00:26,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  78%|███████▊  | 78/100 [01:34<00:24,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  79%|███████▉  | 79/100 [01:35<00:23,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  80%|████████  | 80/100 [01:37<00:21,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  81%|████████  | 81/100 [01:38<00:20,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  82%|████████▏ | 82/100 [01:39<00:18,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  83%|████████▎ | 83/100 [01:40<00:18,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  84%|████████▍ | 84/100 [01:41<00:20,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  85%|████████▌ | 85/100 [01:43<00:20,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  86%|████████▌ | 86/100 [01:44<00:18,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  87%|████████▋ | 87/100 [01:45<00:15,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  88%|████████▊ | 88/100 [01:46<00:14,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  89%|████████▉ | 89/100 [01:47<00:12,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  90%|█████████ | 90/100 [01:48<00:10,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  91%|█████████ | 91/100 [01:49<00:09,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  92%|█████████▏| 92/100 [01:50<00:08,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  93%|█████████▎| 93/100 [01:51<00:07,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  94%|█████████▍| 94/100 [01:53<00:07,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  95%|█████████▌| 95/100 [01:55<00:06,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  96%|█████████▌| 96/100 [01:56<00:05,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  97%|█████████▋| 97/100 [01:57<00:03,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  98%|█████████▊| 98/100 [01:58<00:02,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Export-Seg VAL FULL MC(T=8)]:  99%|█████████▉| 99/100 [01:59<00:01,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skip saving Predictive entropy: invalid shape=(256,)\n",
            "[WARN] Skip saving Mutual information: invalid shape=(256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Export-Seg VAL FULL MC(T=8)]: 100%|██████████| 100/100 [02:00<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seg Export] done -> /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports_validation/epoch_030/seg_val_MC8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Export-Cls VAL FULL]: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VAL-Cls] n=193 acc=0.8394 AURC=0.0434\n",
            "[Cls Export] done -> /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports_validation/epoch_030/cls_val\n",
            "✅ Exports saved to: /content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/exports_validation/epoch_030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# TEST-SET Evaluation + Export (NO TRAINING)\n",
        "# Hybrid CNN–ViT–U-Net (Seg + Cls)\n",
        "# ISIC 2018 Task 1 (Seg Test) + Task 3 (Cls Test)\n",
        "# Physical size: 15mm × 15mm → 256 × 256 px\n",
        "#\n",
        "# Metrics on TEST:\n",
        "#  Seg: Dice, BF-score, HD95(mm), mean entropy/MI (optional)\n",
        "#  Cls: Acc, ECE, Risk–Coverage, AURC, NLL, Brier\n",
        "#\n",
        "# Exports:\n",
        "#  Seg: p_lesion, p_boundary, entropy, MI, transition_width_mm (npy + png with mm axis)\n",
        "#  Cls: logits/probs/labels/uncertainty(entropy) + risk-coverage curve\n",
        "#\n",
        "# Settings:\n",
        "#  - workers=2\n",
        "#  - NEW AMP API\n",
        "#  - load best.pt else latest epoch_XXX.pt\n",
        "# =========================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import math, random, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Performance settings\n",
        "# -----------------------------\n",
        "cv2.setNumThreads(0)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# TEST paths (✅ your setting)\n",
        "# =========================================================\n",
        "SEG_IMAGE_DIR = Path(\"/content/drive/My Drive/isic2018/Test\")\n",
        "SEG_MASK_DIR  = Path(\"/content/drive/My Drive/isic2018/TestTruth\")\n",
        "\n",
        "CLS_IMAGE_DIR = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Test_Input\".strip())\n",
        "CLS_LABEL_CSV = Path(\"/content/drive/My Drive/ISIC_2018_T3/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\".strip())\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"/content/drive/My Drive/seg_class_skin_cancer/Conv_encoder_ViT_U-Net/checkpoints\".strip())\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EXPORT_DIR = CHECKPOINT_DIR.parent / \"exports_test\"\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Physical size\n",
        "# -----------------------------\n",
        "FIELD_SIZE_MM = 15.0\n",
        "IMAGE_SIZE = 256\n",
        "MM_PER_PIXEL = FIELD_SIZE_MM / IMAGE_SIZE\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utils\n",
        "# -----------------------------\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "def list_images_any_ext(folder: Path):\n",
        "    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]\n",
        "    paths = []\n",
        "    for e in exts:\n",
        "        paths.extend(folder.glob(e))\n",
        "    return sorted(paths)\n",
        "\n",
        "def pick_checkpoint(ckpt_dir: Path) -> Path:\n",
        "    best_path = ckpt_dir / \"best.pt\"\n",
        "    if best_path.exists():\n",
        "        return best_path\n",
        "    pts = sorted(ckpt_dir.glob(\"epoch_*.pt\"))\n",
        "    if not pts:\n",
        "        raise FileNotFoundError(f\"No checkpoint found in: {ckpt_dir}\")\n",
        "    def key(p: Path):\n",
        "        m = re.search(r\"epoch_(\\d+)\\.pt$\", p.name)\n",
        "        return int(m.group(1)) if m else -1\n",
        "    pts = sorted(pts, key=key)\n",
        "    return pts[-1]\n",
        "\n",
        "def save_map_with_mm_axis(path_png: Path, arr: np.ndarray, title: str):\n",
        "    arr = np.asarray(arr)\n",
        "    if arr.ndim != 2:\n",
        "        print(f\"[WARN] Skip saving {title}: invalid shape={arr.shape}\")\n",
        "        return\n",
        "    plt.figure(figsize=(5, 4), dpi=150)\n",
        "    plt.imshow(arr, extent=(0, FIELD_SIZE_MM, FIELD_SIZE_MM, 0))\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    plt.xlabel(\"x (mm)\")\n",
        "    plt.ylabel(\"y (mm)\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path_png, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Segmentation (Task 1 TEST)\n",
        "# =========================================================\n",
        "class ISICSegTestDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Robust mask matching:\n",
        "      - <stem>_segmentation.png\n",
        "      - <stem>.png\n",
        "      - also supports .PNG\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir: Path, mask_dir: Path, image_size: int = 256):\n",
        "        self.image_size = image_size\n",
        "        image_paths = list_images_any_ext(image_dir)\n",
        "\n",
        "        pairs = []\n",
        "        for p in image_paths:\n",
        "            stem = p.stem\n",
        "            cand = [\n",
        "                mask_dir / f\"{stem}_segmentation.png\",\n",
        "                mask_dir / f\"{stem}.png\",\n",
        "                mask_dir / f\"{stem}_segmentation.PNG\",\n",
        "                mask_dir / f\"{stem}.PNG\",\n",
        "            ]\n",
        "            mp = None\n",
        "            for c in cand:\n",
        "                if c.exists():\n",
        "                    mp = c\n",
        "                    break\n",
        "            if mp is None:\n",
        "                continue\n",
        "            pairs.append((p, mp))\n",
        "        if len(pairs) == 0:\n",
        "            raise ValueError(f\"No (image,mask) pairs found. Check masks in: {mask_dir}\")\n",
        "\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, mask_path = self.pairs[idx]\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            raise FileNotFoundError(f\"Cannot read mask: {mask_path}\")\n",
        "\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "        img_t = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        mask_t = torch.from_numpy(mask).unsqueeze(0)\n",
        "        return {\"image\": img_t, \"mask\": mask_t, \"id\": img_path.stem}\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Dataset — Classification (Task 3 TEST one-hot CSV)\n",
        "# =========================================================\n",
        "class ISICClsTestDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Expects one-hot CSV:\n",
        "      image, MEL, NV, BCC, AKIEC, BKL, DF, VASC\n",
        "    Converts to 3-class: benign=0, intermediate=1, malignant=2\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir: Path, label_csv: Path, image_size: int = 256):\n",
        "        self.image_dir = image_dir\n",
        "        self.df = pd.read_csv(label_csv)\n",
        "        self.df.columns = self.df.columns.str.strip()\n",
        "        self.image_size = image_size\n",
        "\n",
        "        onehot = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "        if (\"image\" not in self.df.columns) or (not all(c in self.df.columns for c in onehot)):\n",
        "            raise ValueError(f\"CSV missing expected columns. Got: {list(self.df.columns)}\")\n",
        "\n",
        "        self.records = []\n",
        "        for _, row in self.df.iterrows():\n",
        "            img_id = str(row[\"image\"]).strip()\n",
        "            malignant = (row[\"MEL\"] == 1) or (row[\"BCC\"] == 1)\n",
        "            intermediate = (row[\"AKIEC\"] == 1)\n",
        "            benign = (row[\"NV\"] == 1) or (row[\"BKL\"] == 1) or (row[\"DF\"] == 1) or (row[\"VASC\"] == 1)\n",
        "            if malignant:\n",
        "                label = 2\n",
        "            elif intermediate:\n",
        "                label = 1\n",
        "            elif benign:\n",
        "                label = 0\n",
        "            else:\n",
        "                continue\n",
        "            self.records.append((img_id, label))\n",
        "\n",
        "        if len(self.records) == 0:\n",
        "            raise ValueError(\"No valid records in test CSV.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id, label = self.records[idx]\n",
        "        # support jpg/png/jpeg\n",
        "        cand = [\n",
        "            self.image_dir / f\"{img_id}.jpg\",\n",
        "            self.image_dir / f\"{img_id}.png\",\n",
        "            self.image_dir / f\"{img_id}.jpeg\",\n",
        "            self.image_dir / f\"{img_id}.JPG\",\n",
        "            self.image_dir / f\"{img_id}.PNG\",\n",
        "            self.image_dir / f\"{img_id}.JPEG\",\n",
        "        ]\n",
        "        img_path = None\n",
        "        for c in cand:\n",
        "            if c.exists():\n",
        "                img_path = c\n",
        "                break\n",
        "        if img_path is None:\n",
        "            raise FileNotFoundError(f\"Cannot find image for id={img_id} in {self.image_dir}\")\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Cannot read image: {img_path}\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        img_t = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        return {\"image\": img_t, \"label\": torch.tensor(label, dtype=torch.long), \"id\": img_id}\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Model (same as training)\n",
        "# =========================================================\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GELU()\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(ConvBNAct(in_ch, out_ch), ConvBNAct(out_ch, out_ch))\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=32):\n",
        "        super().__init__()\n",
        "        self.e1 = ConvBlock(in_ch, base_ch)\n",
        "        self.e2 = ConvBlock(base_ch, base_ch * 2)\n",
        "        self.e3 = ConvBlock(base_ch * 2, base_ch * 4)\n",
        "        self.e4 = ConvBlock(base_ch * 4, base_ch * 8)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "    def forward(self, x):\n",
        "        f1 = self.e1(x)\n",
        "        f2 = self.e2(self.pool(f1))\n",
        "        f3 = self.e3(self.pool(f2))\n",
        "        f4 = self.e4(self.pool(f3))\n",
        "        return [f1, f2, f3, f4]\n",
        "\n",
        "class ViTBottleneck(nn.Module):\n",
        "    def __init__(self, dim, depth=2, heads=4, drop=0.1):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=dim, nhead=heads, dim_feedforward=dim*4,\n",
        "            dropout=drop, activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, depth)\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        tokens = x.flatten(2).transpose(1, 2)\n",
        "        tokens = self.encoder(tokens)\n",
        "        return tokens.transpose(1, 2).reshape(b, c, h, w)\n",
        "\n",
        "class UNetDecoder(nn.Module):\n",
        "    def __init__(self, base_ch=32, out_ch=1, dropout_p=0.10):\n",
        "        super().__init__()\n",
        "        self.up3 = nn.ConvTranspose2d(base_ch*8, base_ch*4, 2, 2)\n",
        "        self.d3  = ConvBlock(base_ch*8, base_ch*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base_ch*4, base_ch*2, 2, 2)\n",
        "        self.d2  = ConvBlock(base_ch*4, base_ch*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base_ch*2, base_ch, 2, 2)\n",
        "        self.d1  = ConvBlock(base_ch*2, base_ch)\n",
        "        self.drop = nn.Dropout2d(dropout_p) if dropout_p > 0 else nn.Identity()\n",
        "        self.out  = nn.Conv2d(base_ch, out_ch, 1)\n",
        "    def forward(self, feats):\n",
        "        f1, f2, f3, f4 = feats\n",
        "        x = self.up3(f4)\n",
        "        x = self.d3(torch.cat([x, f3], dim=1))\n",
        "        x = self.up2(x)\n",
        "        x = self.d2(torch.cat([x, f2], dim=1))\n",
        "        x = self.up1(x)\n",
        "        x = self.d1(torch.cat([x, f1], dim=1))\n",
        "        x = self.drop(x)\n",
        "        return self.out(x)\n",
        "\n",
        "class HybridMTLModel(nn.Module):\n",
        "    def __init__(self, base_ch=32, num_classes=3, seg_dropout=0.10):\n",
        "        super().__init__()\n",
        "        self.encoder = ConvEncoder(3, base_ch)\n",
        "        self.bottleneck = ViTBottleneck(base_ch*8, depth=2, heads=4, drop=0.1)\n",
        "        self.decoder = UNetDecoder(base_ch, out_ch=1, dropout_p=seg_dropout)\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(base_ch*8, base_ch*8),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(base_ch*8, num_classes),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x)\n",
        "        feats[-1] = self.bottleneck(feats[-1])\n",
        "        seg_logit = self.decoder(feats)\n",
        "        cls_logit = self.cls_head(feats[-1])\n",
        "        return seg_logit, cls_logit\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Metrics (Seg)\n",
        "# =========================================================\n",
        "def mask_to_boundary(mask: np.ndarray) -> np.ndarray:\n",
        "    mask_u8 = (mask > 0).astype(np.uint8)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    er = cv2.erode(mask_u8, kernel, iterations=1)\n",
        "    bd = (mask_u8 - er) > 0\n",
        "    return bd.astype(np.uint8)\n",
        "\n",
        "def bf_score(pred_mask: np.ndarray, gt_mask: np.ndarray, tol_px: int = 2) -> float:\n",
        "    pb = mask_to_boundary(pred_mask)\n",
        "    gb = mask_to_boundary(gt_mask)\n",
        "    if pb.sum() == 0 and gb.sum() == 0:\n",
        "        return 1.0\n",
        "    if pb.sum() == 0 or gb.sum() == 0:\n",
        "        return 0.0\n",
        "    dt_g = ndi.distance_transform_edt(1 - gb)\n",
        "    dt_p = ndi.distance_transform_edt(1 - pb)\n",
        "    prec = (dt_g[pb.astype(bool)] <= tol_px).mean() if pb.sum() > 0 else 0.0\n",
        "    rec  = (dt_p[gb.astype(bool)] <= tol_px).mean() if gb.sum() > 0 else 0.0\n",
        "    return float(2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "\n",
        "def hd95(pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:\n",
        "    pb = mask_to_boundary(pred_mask).astype(bool)\n",
        "    gb = mask_to_boundary(gt_mask).astype(bool)\n",
        "    if pb.sum() == 0 and gb.sum() == 0:\n",
        "        return 0.0\n",
        "    if pb.sum() == 0 or gb.sum() == 0:\n",
        "        h, w = pred_mask.shape\n",
        "        return float(math.sqrt(h*h + w*w))\n",
        "    dt_g = ndi.distance_transform_edt(~gb)\n",
        "    dt_p = ndi.distance_transform_edt(~pb)\n",
        "    d1 = dt_g[pb]\n",
        "    d2 = dt_p[gb]\n",
        "    all_d = np.concatenate([d1, d2], axis=0)\n",
        "    return float(np.percentile(all_d, 95))\n",
        "\n",
        "def dice_score(pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:\n",
        "    inter = (pred_mask & gt_mask).sum()\n",
        "    union = pred_mask.sum() + gt_mask.sum()\n",
        "    return float((2 * inter / (union + 1e-6)) if union > 0 else 1.0)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Metrics (Cls)\n",
        "# =========================================================\n",
        "def softmax_np(logits: np.ndarray) -> np.ndarray:\n",
        "    x = logits - logits.max(axis=1, keepdims=True)\n",
        "    e = np.exp(x)\n",
        "    return e / (e.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def ece_score(probs: np.ndarray, labels: np.ndarray, n_bins: int = 15) -> float:\n",
        "    conf = probs.max(axis=1)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    acc = (pred == labels).astype(np.float32)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        m = (conf > bins[i]) & (conf <= bins[i+1])\n",
        "        if m.any():\n",
        "            ece += abs(acc[m].mean() - conf[m].mean()) * m.mean()\n",
        "    return float(ece)\n",
        "\n",
        "def nll_score(probs: np.ndarray, labels: np.ndarray) -> float:\n",
        "    p = probs[np.arange(len(labels)), labels]\n",
        "    return float((-np.log(p + 1e-12)).mean())\n",
        "\n",
        "def brier_score(probs: np.ndarray, labels: np.ndarray) -> float:\n",
        "    n, k = probs.shape\n",
        "    y = np.zeros((n, k), dtype=np.float32)\n",
        "    y[np.arange(n), labels] = 1.0\n",
        "    return float(((probs - y) ** 2).sum(axis=1).mean())\n",
        "\n",
        "def predictive_entropy(p: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    # for multi-class probs: [N,K]\n",
        "    return -(p * np.log(p + eps)).sum(axis=-1)\n",
        "\n",
        "def risk_coverage_curve(probs: np.ndarray, labels: np.ndarray, uncertainty: np.ndarray):\n",
        "    n = len(labels)\n",
        "    order = np.argsort(uncertainty)\n",
        "    probs_s = probs[order]\n",
        "    labels_s = labels[order]\n",
        "    pred = probs_s.argmax(axis=1)\n",
        "    err = (pred != labels_s).astype(np.float32)\n",
        "    coverages = np.linspace(1/n, 1.0, n)\n",
        "    risks = np.cumsum(err) / (np.arange(n) + 1)\n",
        "    return coverages, risks\n",
        "\n",
        "def aurc(coverages: np.ndarray, risks: np.ndarray) -> float:\n",
        "    return float(np.trapezoid(risks, coverages))\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# MC Dropout (Seg)\n",
        "# =========================================================\n",
        "def enable_dropout_only(model: nn.Module):\n",
        "    model.eval()\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
        "            m.train()\n",
        "\n",
        "def mutual_information(mc_probs: np.ndarray, eps=1e-12) -> np.ndarray:\n",
        "    mean_p = mc_probs.mean(axis=0)\n",
        "    H_mean = -(mean_p*np.log(mean_p+eps) + (1-mean_p)*np.log(1-mean_p+eps))\n",
        "    H_each = -(mc_probs*np.log(mc_probs+eps) + (1-mc_probs)*np.log(1-mc_probs+eps))\n",
        "    return H_mean - H_each.mean(axis=0)\n",
        "\n",
        "def compute_boundary_prob_from_plesion(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy)\n",
        "    g = g / (g.max() + 1e-12)\n",
        "    return g.astype(np.float32)\n",
        "\n",
        "def transition_width_map_mm(p_lesion: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = np.gradient(p_lesion)\n",
        "    g = np.sqrt(gx*gx + gy*gy) + 1e-12\n",
        "    width_px = 0.6 / g\n",
        "    width_mm = width_px * MM_PER_PIXEL\n",
        "    return np.clip(width_mm, 0.0, 10.0).astype(np.float32)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Config\n",
        "# =========================================================\n",
        "@dataclass\n",
        "class TestCfg:\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    amp: bool = True\n",
        "    workers: int = 2\n",
        "\n",
        "    seg_mc_T: int = 8\n",
        "    seg_export_png: bool = True\n",
        "    seg_export_npy: bool = True\n",
        "\n",
        "    cls_export_curve: bool = True\n",
        "\n",
        "cfg = TestCfg()\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Build loaders\n",
        "# =========================================================\n",
        "seg_ds = ISICSegTestDataset(SEG_IMAGE_DIR, SEG_MASK_DIR, image_size=IMAGE_SIZE)\n",
        "cls_ds = ISICClsTestDataset(CLS_IMAGE_DIR, CLS_LABEL_CSV, image_size=IMAGE_SIZE)\n",
        "\n",
        "print(f\"[TEST-SEG] pairs found = {len(seg_ds)}\")\n",
        "print(f\"[TEST-CLS] samples found = {len(cls_ds)}\")\n",
        "\n",
        "common_loader_kwargs = dict(\n",
        "    num_workers=cfg.workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True if cfg.workers > 0 else False,\n",
        "    prefetch_factor=2 if cfg.workers > 0 else None\n",
        ")\n",
        "\n",
        "seg_loader = DataLoader(seg_ds, batch_size=1, shuffle=False, **common_loader_kwargs)\n",
        "cls_loader = DataLoader(cls_ds, batch_size=8, shuffle=False, **common_loader_kwargs)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Load model\n",
        "# =========================================================\n",
        "model = HybridMTLModel(base_ch=32, num_classes=3, seg_dropout=0.10).to(cfg.device)\n",
        "ckpt_path = pick_checkpoint(CHECKPOINT_DIR)\n",
        "ckpt = torch.load(ckpt_path, map_location=cfg.device)\n",
        "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "epoch_loaded = int(ckpt.get(\"epoch\", 0))\n",
        "print(f\"[Load] {ckpt_path.name} | epoch={epoch_loaded}\")\n",
        "\n",
        "OUT_DIR = EXPORT_DIR / f\"epoch_{epoch_loaded:03d}\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# TEST evaluation + export\n",
        "# =========================================================\n",
        "@torch.no_grad()\n",
        "def eval_export_seg_test(mc_T: int):\n",
        "    enable_dropout_only(model)\n",
        "\n",
        "    out_dir = OUT_DIR / f\"seg_test_MC{mc_T}\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    dices, bfs, hd95s_px = [], [], []\n",
        "    ent_means, mi_means = [], []\n",
        "\n",
        "    for b in tqdm(seg_loader, desc=f\"[TEST Seg MC(T={mc_T})]\", leave=True):\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"mask\"].to(cfg.device)\n",
        "        sid = b[\"id\"][0] if isinstance(b[\"id\"], (list, tuple)) else str(b[\"id\"])\n",
        "\n",
        "        mc_probs = []\n",
        "        for _ in range(mc_T):\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "                seg_logit, _ = model(x)\n",
        "                prob = torch.sigmoid(seg_logit).squeeze(0).squeeze(0)  # [H,W]\n",
        "            if prob.ndim == 2:\n",
        "                mc_probs.append(prob.detach().float().cpu().numpy())\n",
        "\n",
        "        if len(mc_probs) == 0:\n",
        "            continue\n",
        "\n",
        "        mc_probs = np.stack(mc_probs, axis=0)\n",
        "        p_lesion = mc_probs.mean(axis=0).astype(np.float32)\n",
        "\n",
        "        pred_mask = (p_lesion > 0.5).astype(np.uint8)\n",
        "        gt_mask = (y.squeeze().detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "        dices.append(dice_score(pred_mask, gt_mask))\n",
        "        bfs.append(bf_score(pred_mask, gt_mask, tol_px=2))\n",
        "        hd95s_px.append(hd95(pred_mask, gt_mask))\n",
        "\n",
        "        ent_map = -(p_lesion*np.log(p_lesion+1e-12) + (1-p_lesion)*np.log(1-p_lesion+1e-12))\n",
        "        mi_map = mutual_information(mc_probs) if mc_T > 1 else np.zeros_like(ent_map)\n",
        "\n",
        "        ent_means.append(float(ent_map.mean()))\n",
        "        mi_means.append(float(mi_map.mean()))\n",
        "\n",
        "        # exports\n",
        "        p_boundary = compute_boundary_prob_from_plesion(p_lesion)\n",
        "        tw_mm = transition_width_map_mm(p_lesion)\n",
        "\n",
        "        if cfg.seg_export_npy:\n",
        "            np.save(out_dir / f\"{sid}_p_lesion.npy\", p_lesion)\n",
        "            np.save(out_dir / f\"{sid}_p_boundary.npy\", p_boundary)\n",
        "            np.save(out_dir / f\"{sid}_entropy.npy\", ent_map.astype(np.float32))\n",
        "            np.save(out_dir / f\"{sid}_mi.npy\", mi_map.astype(np.float32))\n",
        "            np.save(out_dir / f\"{sid}_transition_width_mm.npy\", tw_mm.astype(np.float32))\n",
        "\n",
        "        if cfg.seg_export_png:\n",
        "            save_map_with_mm_axis(out_dir / f\"{sid}_p_lesion.png\", p_lesion, \"p_lesion\")\n",
        "            save_map_with_mm_axis(out_dir / f\"{sid}_p_boundary.png\", p_boundary, \"p_boundary\")\n",
        "            save_map_with_mm_axis(out_dir / f\"{sid}_entropy.png\", ent_map, \"Predictive entropy\")\n",
        "            save_map_with_mm_axis(out_dir / f\"{sid}_mi.png\", mi_map, \"Mutual information\")\n",
        "            save_map_with_mm_axis(out_dir / f\"{sid}_transition_width_mm.png\", tw_mm, \"Transition width (mm)\")\n",
        "\n",
        "    metrics = {\n",
        "        \"dice_mean\": float(np.mean(dices)) if dices else 0.0,\n",
        "        \"bf_mean\": float(np.mean(bfs)) if bfs else 0.0,\n",
        "        \"hd95_mm_mean\": float(np.mean(hd95s_px) * MM_PER_PIXEL) if hd95s_px else 0.0,\n",
        "        \"entropy_mean\": float(np.mean(ent_means)) if ent_means else 0.0,\n",
        "        \"mi_mean\": float(np.mean(mi_means)) if mi_means else 0.0,\n",
        "        \"n\": int(len(dices)),\n",
        "        \"mc_T\": int(mc_T),\n",
        "    }\n",
        "    with open(out_dir / \"seg_test_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(pd.Series(metrics).to_json(indent=2))\n",
        "    print(\"[TEST-SEG]\", metrics)\n",
        "    return metrics\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_export_cls_test():\n",
        "    model.eval()\n",
        "    out_dir = OUT_DIR / \"cls_test\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    all_logits, all_labels = [], []\n",
        "    for b in tqdm(cls_loader, desc=\"[TEST Cls]\", leave=True):\n",
        "        x = b[\"image\"].to(cfg.device)\n",
        "        y = b[\"label\"].to(cfg.device)\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(cfg.amp and cfg.device.startswith(\"cuda\"))):\n",
        "            _, logits = model(x)\n",
        "        all_logits.append(logits.detach().float().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "\n",
        "    logits = np.concatenate(all_logits, axis=0) if all_logits else np.zeros((0, 3), np.float32)\n",
        "    labels = np.concatenate(all_labels, axis=0) if all_labels else np.zeros((0,), np.int64)\n",
        "\n",
        "    probs = softmax_np(logits) if len(labels) else np.zeros_like(logits)\n",
        "    pred = probs.argmax(axis=1) if len(labels) else np.zeros((0,), np.int64)\n",
        "\n",
        "    acc = float((pred == labels).mean()) if len(labels) else 0.0\n",
        "    ece = ece_score(probs, labels, n_bins=15) if len(labels) else 0.0\n",
        "    nll = nll_score(probs, labels) if len(labels) else 0.0\n",
        "    br  = brier_score(probs, labels) if len(labels) else 0.0\n",
        "\n",
        "    unc = predictive_entropy(probs).astype(np.float32) if len(labels) else np.zeros((0,), np.float32)\n",
        "    cov, risk = risk_coverage_curve(probs, labels, unc) if len(labels) else (np.zeros((0,),), np.zeros((0,),))\n",
        "    A = aurc(cov, risk) if len(labels) else 0.0\n",
        "\n",
        "    # save arrays\n",
        "    np.save(out_dir / \"logits.npy\", logits.astype(np.float32))\n",
        "    np.save(out_dir / \"probs.npy\", probs.astype(np.float32))\n",
        "    np.save(out_dir / \"labels.npy\", labels.astype(np.int64))\n",
        "    np.save(out_dir / \"uncertainty_entropy.npy\", unc.astype(np.float32))\n",
        "    if len(labels):\n",
        "        np.save(out_dir / \"risk_coverage_coverage.npy\", cov.astype(np.float32))\n",
        "        np.save(out_dir / \"risk_coverage_risk.npy\", risk.astype(np.float32))\n",
        "\n",
        "    if cfg.cls_export_curve and len(labels):\n",
        "        plt.figure(figsize=(4, 3), dpi=150)\n",
        "        plt.plot(cov, risk)\n",
        "        plt.xlabel(\"Coverage\")\n",
        "        plt.ylabel(\"Risk (error rate)\")\n",
        "        plt.title(f\"TEST Risk–Coverage (AURC={A:.4f})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(out_dir / \"risk_coverage_curve.png\", bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "    metrics = {\n",
        "        \"acc\": float(acc),\n",
        "        \"ece\": float(ece),\n",
        "        \"aurc\": float(A),\n",
        "        \"nll\": float(nll),\n",
        "        \"brier\": float(br),\n",
        "        \"n\": int(len(labels)),\n",
        "    }\n",
        "    with open(out_dir / \"cls_test_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(pd.Series(metrics).to_json(indent=2))\n",
        "    print(\"[TEST-CLS]\", metrics)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# Run TEST\n",
        "# =========================================================\n",
        "seg_metrics = eval_export_seg_test(mc_T=cfg.seg_mc_T)\n",
        "cls_metrics = eval_export_cls_test()\n",
        "\n",
        "summary = {\n",
        "    \"checkpoint\": ckpt_path.name,\n",
        "    \"epoch\": epoch_loaded,\n",
        "    \"seg\": seg_metrics,\n",
        "    \"cls\": cls_metrics,\n",
        "    \"image_size\": IMAGE_SIZE,\n",
        "    \"field_size_mm\": FIELD_SIZE_MM,\n",
        "    \"mm_per_pixel\": MM_PER_PIXEL,\n",
        "}\n",
        "with open(OUT_DIR / \"test_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(pd.Series(summary).to_json(indent=2))\n",
        "\n",
        "print(\"✅ TEST evaluation complete.\")\n",
        "print(\"📁 Saved to:\", OUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9BDTro4gN6z",
        "outputId": "1dc1f6df-1746-4b6e-a757-11f24f9b21bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  _C._set_float32_matmul_precision(precision)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-SEG] pairs found = 1000\n",
            "[TEST-CLS] samples found = 1512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Load] best.pt | epoch=30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[TEST Seg MC(T=8)]:   1%|          | 6/1000 [00:14<34:02,  2.06s/it]"
          ]
        }
      ]
    }
  ]
}